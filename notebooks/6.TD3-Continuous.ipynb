{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD3 HalfCheetah, Ant, Humanoid\n",
    "\n",
    "* TD3 [Fujimoto, Scott, Herke van Hoof, and David Meger. \"Addressing function approximation error in actor-critic methods.\" arXiv preprint arXiv:1802.09477 2018.](https://arxiv.org/pdf/1802.09477.pdf)\n",
    "* gSDE [Smooth Exploration for Robotic Reinforcement Learning 2020](https://arxiv.org/pdf/2005.05719v2.pdf)\n",
    "* Adaptive Parameter Noise - [Parameter Space Noise for Exploration 2017/2018](https://arxiv.org/abs/1706.01905)\n",
    "* https://openai.com/index/better-exploration-with-parameter-noise/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD3 - Twin Delayed Deep Deterministic Policy Gradient\n",
    "\n",
    "The Q-learning algorithm is commonly known to suffer from the overestimation of the value function. This overestimation can propagate through the training iterations and negatively affect the policy. This property directly motivated [Double Q-learning](https://papers.nips.cc/paper/3964-double-q-learning) and [Double DQN](https://arxiv.org/abs/1509.06461): the action selection and Q-value update are decoupled by using two value networks.\n",
    "\n",
    "**Twin Delayed Deep Deterministic** (short for **TD3**; Fujimoto et al., 2018) applied a couple of tricks on DDPG to prevent the overestimation of the value function:\n",
    "\n",
    "#### 1. **Clipped Double Q-learning** \n",
    "\n",
    "In Double Q-Learning, the action selection and Q-value estimation are made by two networks separately. In the DDPG setting, given two deterministic actors $(\\mu_{\\theta_1}, \\mu_{\\theta_2})$ with two corresponding critics $(Q_{w_1}, Q_{w_2})$, the Double Q-learning Bellman targets look like:\n",
    "\n",
    "$$\n",
    "y_1 = r + \\gamma Q_{w_2}(s', \\mu_{\\theta_1}(s'))\\\\\n",
    "y_2 = r + \\gamma Q_{w_1}(s', \\mu_{\\theta_2}(s'))\n",
    "$$\n",
    "\n",
    "However, due to the slow changing policy, these two networks could be too similar to make independent decisions. As a result, for some states we will have $Q_{w_2}(s', \\mu_{\\theta_1}(s')) > Q_{w_1}(s', \\mu_{\\theta_1}(s'))$. This is problematic because $Q_{w_1}(s', \\mu_{\\theta_1}(s'))$ will generally overestimate the true value, and in certain areas of the state space the overestimation will be further exaggerated. The *Clipped Double Q-learning* instead uses the minimum estimation among two so as to favor underestimation bias which is hard to propagate through training:\n",
    "\n",
    "$$\n",
    "y_1 = r + \\gamma \\min_{i=1,2}Q_{w_i}(s', \\mu_{\\theta_1}(s'))\\\\\n",
    "y_2 = r + \\gamma \\min_{i=1,2} Q_{w_i}(s', \\mu_{\\theta_2}(s'))\n",
    "$$\n",
    "\n",
    "#### 2. **Delayed update of Target and Policy Networks**\n",
    "\n",
    "In the actor-critic model, policy and value updates are deeply coupled: Value estimates diverge through overestimation when the policy is poor, and the policy will become poor if the value estimate itself is inaccurate.\n",
    "\n",
    "To reduce the variance, TD3 updates the policy at a lower frequency than the Q-function. The policy network stays the same until the value error is small enough after several updates. The idea is similar to how the periodically-updated target network stay as a stable objective in DQN.\n",
    "\n",
    "#### 3. **Target Policy Smoothing**\n",
    "\n",
    "Given a concern with deterministic policies that they can overfit to narrow peaks in the value function. The authors propose that fitting the value of a small area around the target action:\n",
    "\n",
    "$$y = r + E_\\epsilon [Q_{w'}(s', \\mu_{\\theta '}(s') + \\epsilon)],$$\n",
    "\n",
    "TD3 introduced a smoothing regularization strategy on the value function: adding a small amount of clipped random noises to the selected action and averaging over mini-batches.\n",
    "\n",
    "$$\n",
    "y = r + \\gamma Q_{w'} (s', \\mu_{\\theta '}(s') + \\epsilon) \\\\\n",
    "\\epsilon \\sim \\text{clip}(\\mathcal{N}(0, \\sigma), -c, +c)  \\scriptstyle{\\text{ ; clipped random noises.}}\n",
    "$$\n",
    "\n",
    "The added noise is clipped to keep the target close tothe original action. This approach mimics the idea of SARSA update and enforces that similar actions should have similar values.\n",
    "\n",
    "Here is the final algorithm:\n",
    "\n",
    "<img src=\"../assets/images/td3-algo.png\" width=\"auto\" height=\"auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model - Continuous Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available. Using MPS.\n"
     ]
    }
   ],
   "source": [
    "# Prioritize device: CUDA > MPS > CPU\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "        print(\"CUDA is available. Using CUDA.\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        DEVICE = torch.device(\"mps\")\n",
    "        print(\"MPS backend is available. Using MPS.\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        print(\"Neither CUDA nor MPS is available. Using CPU.\")\n",
    "    return DEVICE\n",
    "\n",
    "DEVICE = set_device()\n",
    "# lets see first on cpu\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "def make_cnn(in_channels: int, feature_dim: int) -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    Return a CNN feature extractor. This is just an example (Atari-style).\n",
    "    Expects input shape: (B, in_channels, 84, 84).\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 32, kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 7 * 7, feature_dim),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "def make_mlp(input_dim: int, output_dim: int, hidden_layers=[400,300], layer_norm=False) -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    Return an MLP (fully-connected) feature extractor.\n",
    "    \"\"\"\n",
    "    layers = OrderedDict()\n",
    "    layer_idx = 0\n",
    "        \n",
    "    for size in hidden_layers:\n",
    "        # Add a linear layer\n",
    "        layers[f\"linear_{layer_idx}\"] = nn.Linear(input_dim, size)\n",
    "        layer_idx += 1\n",
    "        # Add layer normalization\n",
    "        if layer_norm:\n",
    "            layers[f\"layer_norm_{layer_idx}\"] = nn.LayerNorm(size)\n",
    "            layer_idx += 1\n",
    "        # Add activation\n",
    "        layers[f\"relu_{layer_idx}\"] = nn.ReLU()\n",
    "        layer_idx += 1\n",
    "\n",
    "        input_dim = size\n",
    "\n",
    "    # Add the final output layer\n",
    "    layers[f\"linear_{layer_idx}\"] = nn.Linear(input_dim, output_dim)\n",
    "    return nn.Sequential(layers)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_shape, action_size, action_low, action_high, layer_norm=False):\n",
    "        \"\"\"\"\n",
    "        :param obs_shape: Tuple describing observation (e.g. (4,84,84) for images, or (24,) for vectors)\n",
    "        :param action_size: Dimension of the action space (continuous)\n",
    "        :param action_low:  Lower bound for the action (float or array)\n",
    "        :param action_high: Upper bound for the action (float or array)\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        # Check whether obs is an image or a vector\n",
    "        if len(obs_shape) == 3:\n",
    "            # e.g. obs_shape = (channels, height, width)\n",
    "            in_channels = obs_shape[0]\n",
    "            self.base = make_cnn(in_channels, 512)   # => feature dim = 256 (example)\n",
    "            self.fc_actor = make_mlp(512, action_size, [512], layer_norm)\n",
    "        else:\n",
    "            # e.g. obs_shape = (state_dim,)\n",
    "            state_dim = obs_shape[0]\n",
    "            self.base = nn.Identity()\n",
    "            self.fc_actor = make_mlp(state_dim, action_size, [400,300], layer_norm)\n",
    "\n",
    "        # Action scaling\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((action_high - action_low) / 2, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((action_high + action_low) / 2, dtype=torch.float32)\n",
    "        )\n",
    "        # print(self.action_scale)\n",
    "        # print(self.action_bias)\n",
    "\n",
    "\n",
    "    def forward(self, obs:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: obs -> (CNN or Identity) -> MLP -> raw action -> scaled action\n",
    "        \"\"\"\n",
    "        features = self.base(obs)\n",
    "        action = F.tanh(self.fc_actor(features))\n",
    "        return action * self.action_scale + self.action_bias\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Double Critic (Q-Value) Model..\"\"\"\n",
    "\n",
    "    def __init__(self, obs_shape, action_size):\n",
    "        \"\"\"         \n",
    "        :param obs_shape: Tuple describing observation (e.g. (4,84,84) for images, or (24,) for vectors)\n",
    "        :param action_size: Dimension of the action space (continuous)\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # Check whether obs is an image or a vector\n",
    "        if len(obs_shape) == 3:\n",
    "            # e.g. obs_shape = (channels, height, width)\n",
    "            in_channels = obs_shape[0]\n",
    "            self.base = make_cnn(in_channels, 512)   # => feature dim = 256 (example)\n",
    "            self.fc_critic1 = make_mlp(512 + action_size, 1, [512])\n",
    "            self.fc_critic2 = make_mlp(512 + action_size, 1, [512])\n",
    "        else:\n",
    "            # e.g. obs_shape = (state_dim,)\n",
    "            state_dim = obs_shape[0]\n",
    "            self.base = nn.Identity()\n",
    "            self.fc_critic1 = make_mlp(state_dim + action_size, 1, [400,300])\n",
    "            self.fc_critic2 = make_mlp(state_dim + action_size, 1, [400,300])\n",
    "\n",
    "    def forward(self, obs: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: obs -> (CNN or Identity) -> MLP -> value1, value2\n",
    "        \"\"\"\n",
    "        features = self.base(obs)\n",
    "        feature_actions = torch.cat([features, action], dim=-1)\n",
    "        value1 = self.fc_critic1(feature_actions)\n",
    "        value2 = self.fc_critic2(feature_actions)\n",
    "        return value1, value2 \n",
    "    \n",
    "    def forward_critic1(self, obs: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: obs -> (CNN or Identity) -> MLP -> value1\n",
    "        \"\"\"\n",
    "        features = self.base(obs)\n",
    "        value1 = self.fc_critic1(torch.cat([features, action], dim=-1))\n",
    "        return value1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionNoise(object):\n",
    "\n",
    "    def sample(slef):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        \"\"\"Get the current scale of the noise.\"\"\"\n",
    "        return self._scale\n",
    "\n",
    "    @scale.setter\n",
    "    def scale(self, value: float):\n",
    "        \"\"\"\n",
    "        Set the scale of the noise.\n",
    "        :param value: New scale value.\n",
    "        \"\"\"\n",
    "        if value <= 0:\n",
    "            raise ValueError(\"Scale must be a positive value.\")\n",
    "        self._scale = value\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, value: torch.device):\n",
    "        if not isinstance(value, torch.device):\n",
    "            raise ValueError(\"Device must be a torch device\")\n",
    "        self._device = value\n",
    "\n",
    "\n",
    "# https://spinningup.openai.com/en/latest/algorithms/ddpg.html#exploration-vs-exploitation\n",
    "class NormalActionNoise(ActionNoise):\n",
    "    \"\"\"\n",
    "    Normal or Gaussian noise\n",
    "    noiseâˆ¼N(0,Ïƒ2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_dim, scale:float=0.1):\n",
    "        self.action_dim = action_dim\n",
    "        self.scale = scale # Standard deviation of the noise\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def sample(self):\n",
    "        return np.random.normal(0, self.scale, size=self.action_dim)\n",
    "\n",
    "class VectorizedActionNoise:\n",
    "    \"\"\"\n",
    "    A Vectorized action noise for parallel environments.\n",
    "\n",
    "    :param base_noise: Noise generator to use\n",
    "    :param n_envs: Number of parallel environments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_noise: ActionNoise, n_envs: int) -> None:\n",
    "        self.base_noise = base_noise\n",
    "        self.device = base_noise.device\n",
    "        self.noises = [copy.deepcopy(self.base_noise) for _ in range(n_envs)]\n",
    "\n",
    "    def reset(self, indices) -> None:\n",
    "        \"\"\"\n",
    "        Reset all the noise processes, or those listed in indices.\n",
    "\n",
    "        :param indices: The indices to reset. Default: None.\n",
    "            If the parameter is None, then all processes are reset to their initial position.\n",
    "        \"\"\"\n",
    "        if indices is None:\n",
    "            indices = range(len(self.noises))\n",
    "\n",
    "        for index in indices:\n",
    "            self.noises[index].reset()\n",
    "\n",
    "    def sample(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate and stack the action noise from each noise object.\n",
    "        \"\"\"\n",
    "        noise = np.stack([noise.sample() for noise in self.noises])\n",
    "        return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Parameter Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From OpenAI Baselines:\n",
    "https://github.com/openai/baselines/blob/master/baselines/ddpg/noise.py\n",
    "\"\"\"\n",
    "class AdaptiveParamNoiseSpec(object):\n",
    "    def __init__(self, initial_stddev=0.1, desired_action_stddev=0.2, adaptation_coefficient=1.01):\n",
    "        \"\"\"\n",
    "        Note that initial_stddev and current_stddev refer to std of parameter noise, \n",
    "        but desired_action_stddev refers to (as name notes) desired std in action space\n",
    "        \"\"\"\n",
    "        self.initial_stddev = initial_stddev\n",
    "        self.desired_action_stddev = desired_action_stddev\n",
    "        self.adaptation_coefficient = adaptation_coefficient\n",
    "\n",
    "        self.current_stddev = initial_stddev\n",
    "\n",
    "    def adapt(self, distance):\n",
    "        if distance > self.desired_action_stddev:\n",
    "            # Decrease stddev.\n",
    "            self.current_stddev /= self.adaptation_coefficient\n",
    "        else:\n",
    "            # Increase stddev.\n",
    "            self.current_stddev *= self.adaptation_coefficient\n",
    "    \n",
    "    def perturb_actor_parameters(self, actor_local, actor_perturbed, param_name='actor.linear'):\n",
    "        \"\"\"\n",
    "        Apply parameter noise to actor model, for exploration\n",
    "        \n",
    "        :param actor_local: Original actor model.\n",
    "        :param actor_perturbed: Perturbed actor model.\n",
    "        :param param_name: Name of parameteres to be perturbed, example layers included prefix in name 'actor.linear'\n",
    "        \"\"\"\n",
    "        # hard copy the original actor to perturbed actor\n",
    "        actor_perturbed.load_state_dict(actor_local.state_dict().copy())\n",
    "        params = actor_perturbed.state_dict()\n",
    "        for name in params:\n",
    "            if param_name in name: # do only actor and do only linear layers\n",
    "                param = params[name]\n",
    "                param += torch.randn(param.shape) * self.current_stddev\n",
    "\n",
    "    def adapt_param_noise(self, replay_memory, actor_local, actor_perturbed, mini_batch_size):\n",
    "        \"\"\"\n",
    "        Adapt parameter noise by computing the distance between perturbed and unperturbed actions.\n",
    "\n",
    "        :param replay_memory: Replay buffer for sampling states.\n",
    "        :param actor_local: Original actor model.\n",
    "        :param actor_perturbed: Perturbed actor model.\n",
    "        :param mini_batch_size (int): Size of the batch for computing adaptation.\n",
    "        \"\"\"\n",
    "        replay_data = replay_memory.sample(batch_size=mini_batch_size)\n",
    "\n",
    "        states = replay_data['obs']\n",
    "        with torch.no_grad():\n",
    "            unperturbed_actions = actor_local(states)\n",
    "            perturbed_actions = actor_perturbed(states)\n",
    "\n",
    "        # Computes the distance (MSE) between actions from original and perturbed actors.\n",
    "        distance = ((unperturbed_actions - perturbed_actions) ** 2).mean().item()\n",
    "        # adjust the amount of noise given by param noise\n",
    "        self.adapt(distance)\n",
    "\n",
    "    def get_stats(self):\n",
    "        stats = {\n",
    "            'param_noise_stddev': self.current_stddev,\n",
    "        }\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The replay buffer storage collects and stores the following components for each step  $ð‘¡$ in a batch of $ð‘$ parallel environments:\n",
    "- state $s_{t}$\n",
    "- actions $a_{t}$\n",
    "- next state $s_{t+1}$\n",
    "- rewards $r_{t+}$\n",
    "- terminates $m_{t+1}$ - a binary mask to indicate if the environment is terminated (0 if active, 1 entered terminal state)\n",
    "- truncates $tr_{t+1}$ - a binary mask to indicate if the environmnet was truncated due to time limitation (**important to adjust rewards to include next state value**)\n",
    "\n",
    "At each step $ð‘¡$, for environment $ð‘$, the collected data is:\n",
    "\n",
    "$$ \\{s_{t,b}, a_{t,b}, r_{t+1,b}, s_{t+1}, d_{t+1,b}, tr_{t+1,b} \\} $$\n",
    "\n",
    "We use torch for storing here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"    \n",
    "    Replay buffer used in off-policy algorithms like DDPG/SAC/TD3.\n",
    "    \n",
    "    :param obs_dim: Observation dimensions\n",
    "    :param action_dim: Actions dimensions\n",
    "    :param n_envs: Number of parallel environments \n",
    "    :param size: Max number of elements in the buffer\n",
    "    :param device: Device (cpu, cuda, ...) on which the code should be run. \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 obs_dim,\n",
    "                 action_dim:int =1,\n",
    "                 n_envs: int = 1,\n",
    "                 size: int = 1e6,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.device = device\n",
    "        self.n_envs = n_envs\n",
    "\n",
    "        self.pos = 0\n",
    "        self.size = 0\n",
    "\n",
    "        # Adjust buffer size \n",
    "        self.max_size = max(int(size // n_envs), 1)\n",
    "\n",
    "        # Setup the data storage \n",
    "        self.obs = np.zeros((self.max_size, self.n_envs, *self.obs_dim), dtype=np.float32)\n",
    "        self.next_obs = np.zeros((self.max_size, self.n_envs, *self.obs_dim), dtype=np.float32)\n",
    "        self.actions = np.zeros((self.max_size, self.n_envs, self.action_dim), dtype=np.float32)\n",
    "        self.rewards = np.zeros((self.max_size, self.n_envs), dtype=np.float32)\n",
    "        self.terminates = np.zeros((self.max_size, self.n_envs), dtype=np.int8)\n",
    "        # self.truncates = np.zeros((self.size, self.n_envs), dtype=np.int8)\n",
    "\n",
    "    def add(self,\n",
    "            obs: np.ndarray,\n",
    "            next_obs: np.ndarray,\n",
    "            action: np.ndarray,\n",
    "            reward: np.ndarray,\n",
    "            terminates: np.ndarray\n",
    "            ):\n",
    "        self.obs[self.pos] = np.array(obs)\n",
    "        self.next_obs[self.pos] = np.array(next_obs)\n",
    "        self.actions[self.pos] = np.array(action)\n",
    "        self.rewards[self.pos] = np.array(reward)\n",
    "        self.terminates[self.pos] = np.array(terminates)\n",
    "\n",
    "        self.pos = (self.pos + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample(self,\n",
    "               batch_size:int = 32):\n",
    "        \"\"\"\n",
    "        Sample elements from the replay buffer.\n",
    "        \n",
    "        :param batch_size: Number of elements to sample\n",
    "        \"\"\"\n",
    "        batch_indices = np.random.randint(0, self.size, size=batch_size)\n",
    "        # Sample randomly the env idx\n",
    "        env_indices = np.random.randint(0, high=self.n_envs, size=(len(batch_indices),))\n",
    "        # in the end we return exactly batch_size transitions collected even from different agents\n",
    "        # # Extract sampled data\n",
    "        # obs = self.obs[batch_indices, env_indices, :]\n",
    "        # next_obs = self.next_obs[batch_indices, env_indices, :]\n",
    "        # actions = self.actions[batch_indices, env_indices]\n",
    "        # rewards = self.rewards[batch_indices, env_indices]\n",
    "        # dones = self.dones[batch_indices, env_indices]\n",
    "        \n",
    "        # # Convert to torch.Tensor and return as a tuple\n",
    "        # return (\n",
    "        #     self._to_torch(obs),\n",
    "        #     self._to_torch(next_obs),\n",
    "        #     self._to_torch(actions),\n",
    "        #     self._to_torch(rewards),\n",
    "        #     self._to_torch(dones),\n",
    "        # )\n",
    "        data = dict(\n",
    "            obs=self.obs[batch_indices, env_indices, :],\n",
    "            next_obs=self.next_obs[batch_indices, env_indices, :],\n",
    "            actions=self.actions[batch_indices, env_indices],\n",
    "            rewards=self.rewards[batch_indices, env_indices],\n",
    "            # Only use dones that are not due to timeouts\n",
    "            dones=self.terminates[batch_indices, env_indices]\n",
    "        )\n",
    "        return {k: self._to_torch(v) for k,v in data.items()}\n",
    "        \n",
    "\n",
    "    def _to_torch(self, data):\n",
    "        return torch.tensor(data, dtype=torch.float32, device=self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD3 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "\n",
    "from helpers.utils import Logger\n",
    "\n",
    "\n",
    "class TD3Agent:\n",
    "    \"\"\"\n",
    "    Twin Delayed Deep Deterministic Policy Gradient (TD3)\n",
    "    :param env(gym.vector.VectorEnv): Vector Gym Environment to learn from, consists of nEnvs\n",
    "    :param buffer_size: size of the replay buffer\n",
    "    :param mini_batch_size: Minibatch size for each gradient update\n",
    "    :param tau: the soft update coefficient (\"Polyak update\", between 0 and 1) \n",
    "            Î¸_target = Ï„*Î¸_local + (1 - Ï„)*Î¸_target\n",
    "    :param gamma: Discount factor\n",
    "    :param action_noise: the action noise type (None by default), exploration \n",
    "    :param param_noise: the adaptive param noise, exploration \n",
    "    :param policy_delay: Policy and target networks will only be updated once every policy_delay steps\n",
    "            per training steps. The Q values will be updated policy_delay more often (update every training step).\n",
    "    :param target_policy_noise: Standard deviation of Gaussian noise added to target policy\n",
    "            (smoothing noise)\n",
    "    :param target_noise_clip: Limit for absolute value of target policy smoothing noise.\n",
    "    :param actor_lr: The learning rate for Actor(policy)\n",
    "    :param critic_lr: The learning rate for Critic(Q-value)\n",
    "    :param clip_value_loss: Whether clip value loss\n",
    "        This is a parameter specific to the OpenAI implementation. \n",
    "    :param learning_starts:  how many steps of the model to collect transitions for before learning starts\n",
    "    :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                env: gym.vector.VectorEnv,\n",
    "                buffer_size: int = 1e6,\n",
    "                mini_batch_size: int = 128,\n",
    "                tau: float = 0.005,\n",
    "                learning_starts: int = 25000,\n",
    "                action_noise: ActionNoise = None,\n",
    "                param_noise: AdaptiveParamNoiseSpec = None,\n",
    "                gamma: float = 0.99,\n",
    "                policy_delay: int = 2,\n",
    "                target_policy_noise: float = 0.2,\n",
    "                target_noise_clip: float = 0.5,\n",
    "                actor_lr: float = 1e-4,\n",
    "                critic_lr: float = 1e-3,\n",
    "                layer_norm: bool = False,\n",
    "                device: torch.device = torch.device(\"cpu\"),\n",
    "                reward_to_achieve: int = 2500):\n",
    "    \n",
    "        self.env = env\n",
    "        self.n_envs = env.num_envs\n",
    "\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.learning_starts = learning_starts\n",
    "        \n",
    "        self.tau = tau\n",
    "        self.gamma = gamma    \n",
    "        self.policy_delay = policy_delay\n",
    "\n",
    "        self.action_noise = action_noise\n",
    "        self.param_noise = param_noise\n",
    "\n",
    "        self.device = device \n",
    "\n",
    "        action_size = self.env.single_action_space.shape[0]\n",
    "        obs_shape = self.env.single_observation_space.shape \n",
    "        action_low = self.env.single_action_space.low \n",
    "        action_high = self.env.single_action_space.high \n",
    "        \n",
    "        self.action_min = self.env.single_action_space.low[0]\n",
    "        self.action_max = self.env.single_action_space.high[1]\n",
    "\n",
    "        # Scale initially the policy noise and noise clip, sometimes its [-1,1], sometimes [-0.4,0.4], \n",
    "        # need to scale it to make rest of code work perfectly \n",
    "        action_scale = float((self.action_max - self.action_min)/2)\n",
    "        self.target_policy_noise = float(target_policy_noise*action_scale)\n",
    "        self.target_noise_clip = float(target_noise_clip*action_scale)\n",
    "        print(action_scale, self.target_policy_noise, self.target_noise_clip)\n",
    "\n",
    "        # initialize networks\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(obs_shape, action_size, action_low, action_high, layer_norm).to(self.device)\n",
    "        self.actor_target = Actor(obs_shape, action_size, action_low, action_high, layer_norm).to(self.device)\n",
    "        # hard copy the original actor to target actor\n",
    "        self.actor_target.load_state_dict(self.actor_local.state_dict())\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=actor_lr)\n",
    "        \n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(obs_shape, action_size).to(self.device)\n",
    "        self.critic_target = Critic(obs_shape, action_size).to(self.device)\n",
    "        # hard copy the original actor to target actor\n",
    "        self.critic_target.load_state_dict(self.critic_local.state_dict())\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=critic_lr)\n",
    "        \n",
    "        if param_noise is not None:\n",
    "            self.param_noise = param_noise\n",
    "            self.param_noise.current_stddev *= self.param_noise.current_stddev * action_scale\n",
    "            self.param_noise.desired_action_stddev *= self.param_noise.desired_action_stddev * action_scale\n",
    "            self.actor_perturbed = Actor(obs_shape, action_size, action_low, action_high, layer_norm).to(self.device)            \n",
    "        elif action_noise is not None:\n",
    "            self.action_noise = action_noise \n",
    "            self.action_noise.scale = float(self.action_noise.scale*action_scale)\n",
    "            print(self.action_noise.scale)\n",
    "            if self.n_envs > 1:\n",
    "                self.action_noise = VectorizedActionNoise(self.action_noise, self.n_envs)\n",
    "            \n",
    "\n",
    "        # define Replay Memory \n",
    "        self.replay_memory = ReplayBuffer(\n",
    "            obs_shape,\n",
    "            action_size,\n",
    "            n_envs=self.n_envs,\n",
    "            size=buffer_size,\n",
    "            device=self.device)   \n",
    "\n",
    "        # --------- Additional Parameters to think about\n",
    "        self.rollout_steps = 1\n",
    "\n",
    "        # logger initialization \n",
    "        run_name =(\n",
    "            f\"actor_lr{actor_lr}\"\n",
    "            f\"_critic_lr{critic_lr}\"\n",
    "            f\"_gamma{gamma}\"\n",
    "            f\"_nenvs{env.num_envs}\"\n",
    "            f\"_batch{self.mini_batch_size}\"\n",
    "            f\"_tau{tau}\"\n",
    "            f\"_noise{self.action_noise.scale if action_noise is not None else 'param'}\" \n",
    "            f\"_{int(time.time())}\"\n",
    "        )\n",
    "\n",
    "        run_name = \"\".join(run_name)\n",
    "        self.logger = Logger(run_name=run_name, env=env.envs[0].spec.id, algo=\"TD3\")\n",
    "        # Log hyperparameters table\n",
    "        hyperparams = {\n",
    "            \"actor_lr\": actor_lr,\n",
    "            \"critic_lr\": critic_lr,\n",
    "            \"gamma\": gamma,\n",
    "            \"tau\": tau,\n",
    "            \"buffer_size\": buffer_size,\n",
    "            \"mini_batch_size\": mini_batch_size,\n",
    "            \"policy_delay\": policy_delay,\n",
    "            \"target_policy_noise\": target_policy_noise,\n",
    "            \"target_noise_clip\": target_noise_clip,\n",
    "            \"action_noise\": self.action_noise.scale if action_noise is not None else \"param\",\n",
    "        }\n",
    "        self.logger.log_hyperparameters(hyperparams)\n",
    "\n",
    "\n",
    "        self.episode_num = 1\n",
    "        self.best_reward = float('-inf')\n",
    "        self.reward_to_achieve = reward_to_achieve \n",
    "    \n",
    "\n",
    "    def select_action(self, state, add_noise=True):\n",
    "        # if less then learning warm up number of steps, sample randomly, suggested 10000\n",
    "        if self._num_timesteps < self.learning_starts:\n",
    "            return self.env.action_space.sample()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.param_noise is not None and add_noise:\n",
    "                action = self.actor_perturbed(state)\n",
    "            else: \n",
    "                action = self.actor_local(state)\n",
    "       \n",
    "        if self.action_noise is not None and add_noise:\n",
    "            action += torch.tensor(self.action_noise.sample(), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        clipped_actions = action.cpu().numpy().clip(\n",
    "            self.env.action_space.low,\n",
    "            self.env.action_space.high)\n",
    "\n",
    "        return clipped_actions\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        Î¸_target = Ï„*Î¸_local + (1 - Ï„)*Î¸_target\n",
    "\n",
    "        :param local_model: PyTorch model (weights will be copied from)\n",
    "        :param target_model: PyTorch model (weights will be copied to)\n",
    "        :param tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data) \n",
    "    \n",
    "    def collect_rollouts(self):\n",
    "        \"\"\"\n",
    "        Collect experiences and store them into a ``ReplayBuffer``.\n",
    "        \"\"\"\n",
    "        obs = self._last_obs\n",
    "\n",
    "        for _ in range(self.rollout_steps): \n",
    "        \n",
    "            actions = self.select_action(\n",
    "                torch.as_tensor(obs, dtype=torch.float32, device=self.device))\n",
    "\n",
    "            next_obs, rewards, terminates, truncates, infos = self.env.step(actions) \n",
    "            \n",
    "            # Updating global number of steps agent done, while learning\n",
    "            self._num_timesteps += self.n_envs\n",
    "\n",
    "            dones = (terminates | truncates)\n",
    "            \n",
    "            if \"final_info\" in infos:\n",
    "                source_info = infos[\"final_info\"]\n",
    "                self._extract_episode_data(source_info.get('episode'), source_info.get('_episode'))\n",
    "            \n",
    "            self.replay_memory.add(\n",
    "                obs,\n",
    "                next_obs,\n",
    "                actions,\n",
    "                rewards,\n",
    "                terminates\n",
    "            )\n",
    "\n",
    "            # We reset action noise for all the episode reset situations \n",
    "            # It works in case of using noise like OUNoise or etc\n",
    "            for idx, done in enumerate(dones):\n",
    "                if done:\n",
    "                    if self.action_noise is not None:\n",
    "                        kwargs = dict(indices=[idx]) if self.n_envs > 1 else {}\n",
    "                        self.action_noise.reset(**kwargs)\n",
    "            # update most recent \n",
    "            obs = next_obs\n",
    "\n",
    "        # remember last obs for next rollout call\n",
    "        self._last_obs = obs\n",
    "    \n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Update policy and value parameters using given batch of experience tuples.\n",
    "        noised_action = actor_target(next_state) + clipped_noise(0,scale,-c,c)\n",
    "        Q1_next_target, Q2_next_target = critic1_target(next_state, noised_action), critic2_target(next_state, noised_action)\n",
    "        Q_targets = r + Î³ * min(Q1_next_target, Q2_next_target)\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        \"\"\"\n",
    "        self._learn_iterations += 1\n",
    "\n",
    "        replay_data = self.replay_memory.sample(self.mini_batch_size)\n",
    "        states = replay_data['obs']#[256,17]\n",
    "        actions = replay_data['actions'] #[256,6]\n",
    "        rewards = replay_data['rewards'].unsqueeze(-1)# [256,1]\n",
    "        next_states = replay_data['next_obs'] # [256, 17]\n",
    "        dones = replay_data['dones'].unsqueeze(-1)#[256,1]\n",
    "\n",
    "        #---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models        \n",
    "        with torch.no_grad():\n",
    "            clipped_noise = (torch.randn_like(actions, device=self.device) * self.target_policy_noise)\n",
    "            clipped_noise = torch.clamp(\n",
    "                clipped_noise,\n",
    "                -self.target_noise_clip, \n",
    "                self.target_noise_clip\n",
    "            )\n",
    "\n",
    "            next_actions = (self.actor_target(next_states) + clipped_noise).clamp(\n",
    "                self.action_min,\n",
    "                self.action_max\n",
    "            )\n",
    "            \n",
    "            Q1_next_targets, Q2_next_targets = self.critic_target(next_states, next_actions)\n",
    "            Q_next_targets = torch.min(Q1_next_targets, Q2_next_targets)\n",
    "            # Compute Q targets for current states (y_i)\n",
    "            Q_targets = rewards + (self.gamma * (1-dones) * Q_next_targets)\n",
    "\n",
    "        # Compute critic loss \n",
    "        Q1_expected, Q2_expected = self.critic_local(states, actions)\n",
    "        Q1_loss = F.mse_loss(Q1_expected, Q_targets)\n",
    "        Q2_loss = F.mse_loss(Q2_expected, Q_targets)\n",
    "        critic_loss = Q1_loss + Q2_loss\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        #---------------------------- Delayed Actor Update ------------------------------ #\n",
    "        actor_loss = torch.tensor(0.0)\n",
    "        if self._learn_iterations % self.policy_delay:\n",
    "            # Compute actor losse\n",
    "            actions = self.actor_local(states)\n",
    "            q1, q2 = self.critic_local.forward(states, actions)\n",
    "            actor_loss = -torch.min(q1, q2).mean()\n",
    "\n",
    "\n",
    "            # Minimize the loss\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "       \n",
    "            #-------------------------- update target network ----------------------- # \n",
    "            self.soft_update(self.actor_local, self.actor_target, self.tau)\n",
    "            self.soft_update(self.critic_local, self.critic_target, self.tau)\n",
    "\n",
    "        return( \n",
    "            Q1_loss.item(),\n",
    "            Q2_loss.item(),\n",
    "            critic_loss.item(), \n",
    "            actor_loss.item()\n",
    "        )     \n",
    "\n",
    "    def train(self, total_timesteps: int = 1e6, eval_frequency: int = 5000, param_noise_adaption_interval: int=50):\n",
    "        \"\"\"\n",
    "        Train the agent\n",
    "        \"\"\"\n",
    "        obs, _ = self.env.reset()\n",
    "        self._last_obs = obs\n",
    "\n",
    "        self._num_timesteps = 0\n",
    "        self._learn_iterations = 0 #used to control the policy frequency\n",
    "        self.episode_rewards = deque(maxlen=20)\n",
    "        self.episode_lengths = deque(maxlen=20)\n",
    "        eval_frequency = (eval_frequency // self.n_envs) * self.n_envs  # Make divisible by n_envs\n",
    "    \n",
    "        q1_loss, q2_loss, critic_loss, actor_loss = 0.0,0.0,0.0,0.0\n",
    "        while self._num_timesteps < total_timesteps:\n",
    "            \n",
    "            if self._num_timesteps > self.learning_starts and self.param_noise is not None:\n",
    "                self.param_noise.perturb_actor_parameters(self.actor_local, self.actor_perturbed, 'fc_actor.linear')\n",
    "\n",
    "            for _ in range(param_noise_adaption_interval):\n",
    "                # Collect rollouts\n",
    "                self.collect_rollouts()\n",
    "\n",
    "                if self._num_timesteps > self.learning_starts and \\\n",
    "                    len(self.replay_memory) > self.mini_batch_size:\n",
    "                    q1_loss, q2_loss, critic_loss, _actor_loss = self.learn()\n",
    "                    # a little bit hack, to keep seeing last non_zero actor_loss\n",
    "                    if _actor_loss:\n",
    "                        actor_loss = _actor_loss\n",
    "        \n",
    "            # Adapt each epoch, param noise \n",
    "            if self.param_noise is not None:\n",
    "                self.param_noise.adapt_param_noise(self.replay_memory, self.actor_local, self.actor_perturbed, self.mini_batch_size)\n",
    "\n",
    "            # Do some logging each log_interval\n",
    "            if self._num_timesteps % eval_frequency == 0:\n",
    "                mean_rewards = np.mean(self.episode_rewards)\n",
    "                median_rewards = np.median(self.episode_rewards)\n",
    "                min_rewards = np.min(self.episode_rewards)\n",
    "                max_rewards = np.max(self.episode_rewards)\n",
    "                \n",
    "                print(\n",
    "                    \"Num timesteps {}/{} Mean Length {:.1f}\\n\"\n",
    "                    \"Loss Actor {:.4f} Q1/Q2/Critic {:.4f}/{:.4f}/{:.4} \\n\"\n",
    "                    \"Last {} training episodes: mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\"\n",
    "                    .format(\n",
    "                        self._num_timesteps, total_timesteps, np.mean(self.episode_lengths),\n",
    "                        actor_loss, q1_loss, q2_loss, critic_loss,\n",
    "                        len(self.episode_rewards), mean_rewards,\n",
    "                        median_rewards, min_rewards, max_rewards\n",
    "                    )\n",
    "                )\n",
    "             \n",
    "        print('Saving last...')\n",
    "        self._save_model('torch.model')\n",
    "\n",
    "    def _save_model(self, filename: str):\n",
    "        \"\"\"Save the current model state dictionaries and normalization info to a file in logger.dir_name.\"\"\"\n",
    "        model_path = os.path.join(self.logger.dir_name, filename)\n",
    "        \n",
    "        save_data = {\n",
    "            \"actor\": self.actor_local.state_dict(),\n",
    "            \"critic\": self.critic_local.state_dict(),\n",
    "        }\n",
    "\n",
    "        torch.save(save_data, model_path)\n",
    "\n",
    "\n",
    "    def _extract_episode_data(self, episode_data, episode_flags):\n",
    "        \"\"\"\n",
    "        Extract data for environments where '_episode' is True and append it to \n",
    "        self.episode_info_buffer deque\n",
    "            {'r': -21.0, '_r': True, 'l': 944, '_l': True, 't': 5.089006, '_t': True}- example\n",
    "            r - cumulative reward\n",
    "            l - episode length\n",
    "            t - elapsed time since beginning of episode\n",
    "\n",
    "        :param episode_data: dict, data from environments\n",
    "        :param episode_flags: np.ndarray, boolean array indicating done environments\n",
    "        \"\"\"\n",
    "        done_envs = np.where(episode_flags)[0]  # Get indices of done environments\n",
    "    \n",
    "        for env_index in done_envs:\n",
    "            env_specific_data = {}\n",
    "            for key, value in episode_data.items():\n",
    "                if isinstance(value, np.ndarray):  # Ensure it's an array\n",
    "                    env_specific_data[key] = value[env_index]\n",
    "            reward = env_specific_data['r']\n",
    "            length = env_specific_data['l']\n",
    "            self.logger.add_scalar('reward', reward, self.episode_num)\n",
    "            self.logger.add_scalar('length', length, self.episode_num)        \n",
    "            self.episode_rewards.append(reward)\n",
    "            self.episode_lengths.append(length)\n",
    "            self.episode_num += 1\n",
    "        \n",
    "        #Save the best model\n",
    "        mean_rewards = np.mean(self.episode_rewards)\n",
    "        if  mean_rewards > self.reward_to_achieve and mean_rewards > self.best_reward:\n",
    "            self.best_reward = mean_rewards\n",
    "            self._save_model('best-torch.model')\n",
    "            print(f\"Saved best model with min rewards {mean_rewards:.2f}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Example - HalfCheetah-v5\n",
    "\n",
    "Setup the envs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.2 0.5\n",
      "0.1\n",
      "----------------------------------------------------------------------------\n",
      "| Hyperparams                    | Values                                  |\n",
      "----------------------------------------------------------------------------\n",
      "| actor_lr                       | 0.0003                                  |\n",
      "| critic_lr                      | 0.0003                                  |\n",
      "| gamma                          | 0.99                                    |\n",
      "| tau                            | 0.005                                   |\n",
      "| buffer_size                    | 1000000.0                               |\n",
      "| mini_batch_size                | 256                                     |\n",
      "| policy_delay                   | 2                                       |\n",
      "| target_policy_noise            | 0.2                                     |\n",
      "| target_noise_clip              | 0.5                                     |\n",
      "| action_noise                   | 0.1                                     |\n",
      "----------------------------------------------------------------------------\n",
      "Num timesteps 10000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 10 training episodes: mean/median reward -326.9/-313.8, min/max reward -436.5/-210.0\n",
      "Num timesteps 20000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 20 training episodes: mean/median reward -288.4/-278.2, min/max reward -436.5/-158.7\n",
      "Num timesteps 30000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -0.9240 Q1/Q2/Critic 0.7463/0.7622/1.509 \n",
      "Last 20 training episodes: mean/median reward -295.6/-263.4, min/max reward -547.1/-158.7\n",
      "Num timesteps 40000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -8.0835 Q1/Q2/Critic 1.0821/1.1650/2.247 \n",
      "Last 20 training episodes: mean/median reward -136.7/-255.5, min/max reward -757.5/723.9\n",
      "Num timesteps 50000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -21.1258 Q1/Q2/Critic 1.2045/1.4661/2.671 \n",
      "Last 20 training episodes: mean/median reward 403.9/472.2, min/max reward -757.5/1575.4\n",
      "Num timesteps 60000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -42.3858 Q1/Q2/Critic 2.3219/2.6702/4.992 \n",
      "Last 20 training episodes: mean/median reward 1264.9/1401.5, min/max reward -391.2/2208.2\n",
      "Num timesteps 70000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -65.6782 Q1/Q2/Critic 3.5972/4.0561/7.653 \n",
      "Last 20 training episodes: mean/median reward 2095.4/1991.4, min/max reward 1303.8/3352.4\n",
      "Saved best model with min rewards 2537.58\n",
      "Saved best model with min rewards 2636.44\n",
      "Saved best model with min rewards 2709.64\n",
      "Num timesteps 80000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -87.2093 Q1/Q2/Critic 5.8563/5.1885/11.04 \n",
      "Last 20 training episodes: mean/median reward 2709.6/2856.6, min/max reward 1305.1/3672.3\n",
      "Saved best model with min rewards 2768.79\n",
      "Saved best model with min rewards 2884.66\n",
      "Saved best model with min rewards 2942.44\n",
      "Saved best model with min rewards 3039.35\n",
      "Saved best model with min rewards 3098.52\n",
      "Saved best model with min rewards 3153.09\n",
      "Saved best model with min rewards 3216.86\n",
      "Saved best model with min rewards 3266.25\n",
      "Saved best model with min rewards 3373.13\n",
      "Saved best model with min rewards 3406.73\n",
      "Num timesteps 90000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -125.2314 Q1/Q2/Critic 6.4280/6.1167/12.54 \n",
      "Last 20 training episodes: mean/median reward 3406.7/3627.7, min/max reward 1518.7/4024.3\n",
      "Saved best model with min rewards 3523.61\n",
      "Saved best model with min rewards 3563.08\n",
      "Saved best model with min rewards 3607.42\n",
      "Saved best model with min rewards 3732.82\n",
      "Saved best model with min rewards 3777.45\n",
      "Saved best model with min rewards 3828.48\n",
      "Saved best model with min rewards 3876.34\n",
      "Saved best model with min rewards 3911.19\n",
      "Saved best model with min rewards 3944.94\n",
      "Saved best model with min rewards 3951.65\n",
      "Num timesteps 100000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -153.1702 Q1/Q2/Critic 6.5134/7.4100/13.92 \n",
      "Last 20 training episodes: mean/median reward 3951.7/3928.5, min/max reward 3536.6/4389.2\n",
      "Saved best model with min rewards 3995.33\n",
      "Saved best model with min rewards 4046.46\n",
      "Saved best model with min rewards 4089.64\n",
      "Saved best model with min rewards 4147.41\n",
      "Saved best model with min rewards 4164.68\n",
      "Saved best model with min rewards 4207.04\n",
      "Saved best model with min rewards 4251.12\n",
      "Saved best model with min rewards 4282.16\n",
      "Saved best model with min rewards 4323.26\n",
      "Num timesteps 110000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -184.3323 Q1/Q2/Critic 7.7615/8.0839/15.85 \n",
      "Last 20 training episodes: mean/median reward 4323.3/4377.1, min/max reward 3450.8/4846.2\n",
      "Saved best model with min rewards 4365.92\n",
      "Saved best model with min rewards 4372.86\n",
      "Num timesteps 120000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -209.2289 Q1/Q2/Critic 12.6377/14.8003/27.44 \n",
      "Last 20 training episodes: mean/median reward 4250.1/4668.5, min/max reward 740.6/5115.4\n",
      "Saved best model with min rewards 4373.09\n",
      "Num timesteps 130000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -237.6763 Q1/Q2/Critic 26.1647/24.6248/50.79 \n",
      "Last 20 training episodes: mean/median reward 4373.1/4889.0, min/max reward 740.6/5134.2\n",
      "Saved best model with min rewards 4379.51\n",
      "Saved best model with min rewards 4589.76\n",
      "Saved best model with min rewards 4609.28\n",
      "Saved best model with min rewards 4620.22\n",
      "Saved best model with min rewards 4708.49\n",
      "Saved best model with min rewards 4729.92\n",
      "Saved best model with min rewards 4738.85\n",
      "Saved best model with min rewards 4741.03\n",
      "Saved best model with min rewards 4747.62\n",
      "Saved best model with min rewards 4940.98\n",
      "Num timesteps 140000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -252.8702 Q1/Q2/Critic 65.0851/68.3843/133.5 \n",
      "Last 20 training episodes: mean/median reward 4941.0/5042.4, min/max reward 3609.1/5247.3\n",
      "Saved best model with min rewards 4969.22\n",
      "Saved best model with min rewards 4984.09\n",
      "Saved best model with min rewards 5016.30\n",
      "Saved best model with min rewards 5101.27\n",
      "Saved best model with min rewards 5106.10\n",
      "Saved best model with min rewards 5112.34\n",
      "Saved best model with min rewards 5123.15\n",
      "Saved best model with min rewards 5130.12\n",
      "Saved best model with min rewards 5147.18\n",
      "Saved best model with min rewards 5161.74\n",
      "Num timesteps 150000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -275.1978 Q1/Q2/Critic 61.0953/61.1705/122.3 \n",
      "Last 20 training episodes: mean/median reward 5161.7/5188.8, min/max reward 4931.8/5384.2\n",
      "Saved best model with min rewards 5184.92\n",
      "Saved best model with min rewards 5202.28\n",
      "Saved best model with min rewards 5208.95\n",
      "Saved best model with min rewards 5214.61\n",
      "Saved best model with min rewards 5235.19\n",
      "Saved best model with min rewards 5236.42\n",
      "Saved best model with min rewards 5238.85\n",
      "Saved best model with min rewards 5252.41\n",
      "Num timesteps 160000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -290.8339 Q1/Q2/Critic 11.7630/11.1204/22.88 \n",
      "Last 20 training episodes: mean/median reward 5243.9/5244.0, min/max reward 4971.8/5471.1\n",
      "Num timesteps 170000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -299.5097 Q1/Q2/Critic 17.2990/16.7594/34.06 \n",
      "Last 20 training episodes: mean/median reward 4815.2/5248.2, min/max reward 1466.2/5471.1\n",
      "Num timesteps 180000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -310.4356 Q1/Q2/Critic 11.7507/13.6864/25.44 \n",
      "Last 20 training episodes: mean/median reward 4655.5/5241.4, min/max reward 1466.2/5460.6\n",
      "Num timesteps 190000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -316.6947 Q1/Q2/Critic 75.8933/75.0525/150.9 \n",
      "Last 20 training episodes: mean/median reward 5181.5/5388.0, min/max reward 1543.6/5552.4\n",
      "Saved best model with min rewards 5378.22\n",
      "Saved best model with min rewards 5386.70\n",
      "Saved best model with min rewards 5406.10\n",
      "Saved best model with min rewards 5421.62\n",
      "Saved best model with min rewards 5423.89\n",
      "Saved best model with min rewards 5425.74\n",
      "Num timesteps 200000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -330.4854 Q1/Q2/Critic 10.2387/10.6009/20.84 \n",
      "Last 20 training episodes: mean/median reward 5425.7/5433.6, min/max reward 5161.0/5634.4\n",
      "Saved best model with min rewards 5437.87\n",
      "Saved best model with min rewards 5439.04\n",
      "Saved best model with min rewards 5446.99\n",
      "Saved best model with min rewards 5456.58\n",
      "Saved best model with min rewards 5469.98\n",
      "Saved best model with min rewards 5470.86\n",
      "Num timesteps 210000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -347.9892 Q1/Q2/Critic 11.7548/9.7424/21.5 \n",
      "Last 20 training episodes: mean/median reward 5470.9/5474.8, min/max reward 5161.0/5634.4\n",
      "Saved best model with min rewards 5478.45\n",
      "Saved best model with min rewards 5478.73\n",
      "Saved best model with min rewards 5478.80\n",
      "Saved best model with min rewards 5488.52\n",
      "Saved best model with min rewards 5513.79\n",
      "Num timesteps 220000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -344.1517 Q1/Q2/Critic 15.2024/15.3933/30.6 \n",
      "Last 20 training episodes: mean/median reward 5513.3/5519.7, min/max reward 5305.4/5666.4\n",
      "Saved best model with min rewards 5521.99\n",
      "Saved best model with min rewards 5527.34\n",
      "Saved best model with min rewards 5532.19\n",
      "Saved best model with min rewards 5532.83\n",
      "Saved best model with min rewards 5534.23\n",
      "Saved best model with min rewards 5538.77\n",
      "Num timesteps 230000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -357.6628 Q1/Q2/Critic 64.6356/62.8015/127.4 \n",
      "Last 20 training episodes: mean/median reward 5538.8/5558.4, min/max reward 5305.4/5696.4\n",
      "Saved best model with min rewards 5542.94\n",
      "Saved best model with min rewards 5547.84\n",
      "Saved best model with min rewards 5565.29\n",
      "Saved best model with min rewards 5578.20\n",
      "Saved best model with min rewards 5593.17\n",
      "Saved best model with min rewards 5597.75\n",
      "Saved best model with min rewards 5606.66\n",
      "Saved best model with min rewards 5610.99\n",
      "Num timesteps 240000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -364.9340 Q1/Q2/Critic 102.4585/105.8011/208.3 \n",
      "Last 20 training episodes: mean/median reward 5605.3/5616.1, min/max reward 5429.7/5748.8\n",
      "Saved best model with min rewards 5616.63\n",
      "Saved best model with min rewards 5622.25\n",
      "Saved best model with min rewards 5627.52\n",
      "Saved best model with min rewards 5635.29\n",
      "Saved best model with min rewards 5642.85\n",
      "Saved best model with min rewards 5643.31\n",
      "Num timesteps 250000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -372.4401 Q1/Q2/Critic 66.3464/68.1371/134.5 \n",
      "Last 20 training episodes: mean/median reward 5640.2/5634.3, min/max reward 5505.5/5784.0\n",
      "Saved best model with min rewards 5643.68\n",
      "Saved best model with min rewards 5644.10\n",
      "Num timesteps 260000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -380.6801 Q1/Q2/Critic 61.8048/63.3051/125.1 \n",
      "Last 20 training episodes: mean/median reward 5458.1/5644.5, min/max reward 1817.1/5803.2\n",
      "Num timesteps 270000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -385.0035 Q1/Q2/Critic 221.8287/216.4683/438.3 \n",
      "Last 20 training episodes: mean/median reward 5480.5/5670.6, min/max reward 1817.1/5803.2\n",
      "Saved best model with min rewards 5680.61\n",
      "Saved best model with min rewards 5683.91\n",
      "Num timesteps 280000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -379.7830 Q1/Q2/Critic 11.7445/11.3389/23.08 \n",
      "Last 20 training episodes: mean/median reward 5676.6/5699.4, min/max reward 5519.1/5801.9\n",
      "Saved best model with min rewards 5685.12\n",
      "Saved best model with min rewards 5688.80\n",
      "Saved best model with min rewards 5709.57\n",
      "Saved best model with min rewards 5716.14\n",
      "Saved best model with min rewards 5721.65\n",
      "Saved best model with min rewards 5721.71\n",
      "Saved best model with min rewards 5725.78\n",
      "Num timesteps 290000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -386.2003 Q1/Q2/Critic 17.1182/20.1378/37.26 \n",
      "Last 20 training episodes: mean/median reward 5725.8/5728.1, min/max reward 5527.2/5934.5\n",
      "Saved best model with min rewards 5729.42\n",
      "Saved best model with min rewards 5733.67\n",
      "Saved best model with min rewards 5742.84\n",
      "Saved best model with min rewards 5747.55\n",
      "Saved best model with min rewards 5757.41\n",
      "Saved best model with min rewards 5763.70\n",
      "Num timesteps 300000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -399.5688 Q1/Q2/Critic 54.5961/52.8697/107.5 \n",
      "Last 20 training episodes: mean/median reward 5763.7/5744.2, min/max reward 5641.5/5934.5\n",
      "Saved best model with min rewards 5770.04\n",
      "Num timesteps 310000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -405.1233 Q1/Q2/Critic 14.0985/13.1738/27.27 \n",
      "Last 20 training episodes: mean/median reward 5652.3/5771.8, min/max reward 3379.5/5936.6\n",
      "Num timesteps 320000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -410.0240 Q1/Q2/Critic 15.1706/18.0868/33.26 \n",
      "Last 20 training episodes: mean/median reward 5698.7/5795.9, min/max reward 3379.5/6018.5\n",
      "Saved best model with min rewards 5816.04\n",
      "Saved best model with min rewards 5827.55\n",
      "Saved best model with min rewards 5835.04\n",
      "Saved best model with min rewards 5835.50\n",
      "Saved best model with min rewards 5839.00\n",
      "Saved best model with min rewards 5840.55\n",
      "Saved best model with min rewards 5844.16\n",
      "Num timesteps 330000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -403.6052 Q1/Q2/Critic 89.9352/94.1778/184.1 \n",
      "Last 20 training episodes: mean/median reward 5844.2/5851.5, min/max reward 5704.8/6018.5\n",
      "Saved best model with min rewards 5845.23\n",
      "Saved best model with min rewards 5857.88\n",
      "Saved best model with min rewards 5867.33\n",
      "Saved best model with min rewards 5870.00\n",
      "Saved best model with min rewards 5877.84\n",
      "Saved best model with min rewards 5885.74\n",
      "Num timesteps 340000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -414.4058 Q1/Q2/Critic 8.0823/8.5104/16.59 \n",
      "Last 20 training episodes: mean/median reward 5665.0/5874.6, min/max reward 1386.0/6030.8\n",
      "Num timesteps 350000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -410.8080 Q1/Q2/Critic 9.9727/10.4304/20.4 \n",
      "Last 20 training episodes: mean/median reward 5666.2/5885.1, min/max reward 1386.0/6030.8\n",
      "Num timesteps 360000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -423.3899 Q1/Q2/Critic 8.5851/10.1946/18.78 \n",
      "Last 20 training episodes: mean/median reward 5878.3/5883.0, min/max reward 5689.1/6044.0\n",
      "Saved best model with min rewards 5888.76\n",
      "Saved best model with min rewards 5891.88\n",
      "Saved best model with min rewards 5904.12\n",
      "Saved best model with min rewards 5906.30\n",
      "Saved best model with min rewards 5919.41\n",
      "Num timesteps 370000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -424.5161 Q1/Q2/Critic 7.8271/7.8593/15.69 \n",
      "Last 20 training episodes: mean/median reward 5919.4/5906.9, min/max reward 5766.7/6091.7\n",
      "Saved best model with min rewards 5923.60\n",
      "Saved best model with min rewards 5929.45\n",
      "Saved best model with min rewards 5930.80\n",
      "Saved best model with min rewards 5931.46\n",
      "Saved best model with min rewards 5938.15\n",
      "Saved best model with min rewards 5943.87\n",
      "Saved best model with min rewards 5949.15\n",
      "Num timesteps 380000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -432.3763 Q1/Q2/Critic 16.4274/14.3405/30.77 \n",
      "Last 20 training episodes: mean/median reward 5940.6/5957.1, min/max reward 5766.7/6091.7\n",
      "Saved best model with min rewards 5954.80\n",
      "Saved best model with min rewards 5960.48\n",
      "Saved best model with min rewards 5962.64\n",
      "Num timesteps 390000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -423.2218 Q1/Q2/Critic 8.8898/10.1311/19.02 \n",
      "Last 20 training episodes: mean/median reward 5954.5/5946.8, min/max reward 5768.6/6100.9\n",
      "Saved best model with min rewards 5972.12\n",
      "Num timesteps 400000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -431.9047 Q1/Q2/Critic 14.7645/13.6308/28.4 \n",
      "Last 20 training episodes: mean/median reward 5961.5/5949.0, min/max reward 5819.1/6105.2\n",
      "Saved best model with min rewards 5974.76\n",
      "Saved best model with min rewards 5981.74\n",
      "Saved best model with min rewards 5991.53\n",
      "Saved best model with min rewards 5994.86\n",
      "Num timesteps 410000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -442.1935 Q1/Q2/Critic 72.6562/73.6143/146.3 \n",
      "Last 20 training episodes: mean/median reward 5992.1/5997.2, min/max reward 5819.1/6134.1\n",
      "Saved best model with min rewards 6002.10\n",
      "Saved best model with min rewards 6010.49\n",
      "Saved best model with min rewards 6011.67\n",
      "Saved best model with min rewards 6015.65\n",
      "Saved best model with min rewards 6023.25\n",
      "Saved best model with min rewards 6025.38\n",
      "Num timesteps 420000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -441.0994 Q1/Q2/Critic 10.5404/10.5667/21.11 \n",
      "Last 20 training episodes: mean/median reward 6025.4/6028.4, min/max reward 5906.1/6134.1\n",
      "Saved best model with min rewards 6025.93\n",
      "Saved best model with min rewards 6030.14\n",
      "Saved best model with min rewards 6036.12\n",
      "Saved best model with min rewards 6040.88\n",
      "Saved best model with min rewards 6047.36\n",
      "Saved best model with min rewards 6057.58\n",
      "Num timesteps 430000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -448.5685 Q1/Q2/Critic 9.3011/8.2049/17.51 \n",
      "Last 20 training episodes: mean/median reward 6057.6/6059.0, min/max reward 5906.1/6202.8\n",
      "Saved best model with min rewards 6059.10\n",
      "Saved best model with min rewards 6065.93\n",
      "Saved best model with min rewards 6068.06\n",
      "Saved best model with min rewards 6076.64\n",
      "Saved best model with min rewards 6083.66\n",
      "Saved best model with min rewards 6091.85\n",
      "Saved best model with min rewards 6092.55\n",
      "Saved best model with min rewards 6095.01\n",
      "Num timesteps 440000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -441.4261 Q1/Q2/Critic 6.6231/8.2781/14.9 \n",
      "Last 20 training episodes: mean/median reward 6095.0/6107.8, min/max reward 5995.6/6202.8\n",
      "Saved best model with min rewards 6098.02\n",
      "Saved best model with min rewards 6100.30\n",
      "Saved best model with min rewards 6100.88\n",
      "Saved best model with min rewards 6108.13\n",
      "Saved best model with min rewards 6113.69\n",
      "Num timesteps 450000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -445.7842 Q1/Q2/Critic 16.6687/16.2700/32.94 \n",
      "Last 20 training episodes: mean/median reward 5836.5/6108.3, min/max reward 950.5/6196.1\n",
      "Num timesteps 460000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -443.4139 Q1/Q2/Critic 9.7945/8.6528/18.45 \n",
      "Last 20 training episodes: mean/median reward 5859.2/6086.1, min/max reward 950.5/6328.8\n",
      "Saved best model with min rewards 6168.24\n",
      "Num timesteps 470000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -450.7617 Q1/Q2/Critic 11.1885/9.8318/21.02 \n",
      "Last 20 training episodes: mean/median reward 6168.2/6183.6, min/max reward 6020.8/6331.1\n",
      "Saved best model with min rewards 6170.94\n",
      "Saved best model with min rewards 6181.43\n",
      "Saved best model with min rewards 6183.68\n",
      "Saved best model with min rewards 6185.96\n",
      "Saved best model with min rewards 6200.35\n",
      "Saved best model with min rewards 6206.77\n",
      "Num timesteps 480000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -465.3063 Q1/Q2/Critic 11.5373/9.2846/20.82 \n",
      "Last 20 training episodes: mean/median reward 6206.8/6205.6, min/max reward 6020.8/6331.1\n",
      "Saved best model with min rewards 6209.52\n",
      "Saved best model with min rewards 6209.71\n",
      "Saved best model with min rewards 6211.32\n",
      "Saved best model with min rewards 6221.29\n",
      "Num timesteps 490000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -450.9197 Q1/Q2/Critic 12.9937/15.6600/28.65 \n",
      "Last 20 training episodes: mean/median reward 6211.0/6210.8, min/max reward 6078.0/6315.5\n",
      "Saved best model with min rewards 6222.54\n",
      "Saved best model with min rewards 6230.28\n",
      "Num timesteps 500000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -457.8040 Q1/Q2/Critic 8.3474/8.4085/16.76 \n",
      "Last 20 training episodes: mean/median reward 6227.3/6227.4, min/max reward 6078.0/6389.3\n",
      "Saved best model with min rewards 6231.96\n",
      "Saved best model with min rewards 6249.51\n",
      "Saved best model with min rewards 6251.45\n",
      "Saved best model with min rewards 6259.55\n",
      "Saved best model with min rewards 6266.42\n",
      "Saved best model with min rewards 6267.45\n",
      "Saved best model with min rewards 6274.79\n",
      "Saved best model with min rewards 6280.72\n",
      "Saved best model with min rewards 6291.65\n",
      "Num timesteps 510000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -458.0242 Q1/Q2/Critic 8.6102/7.9563/16.57 \n",
      "Last 20 training episodes: mean/median reward 6291.7/6282.9, min/max reward 6136.7/6458.8\n",
      "Saved best model with min rewards 6295.46\n",
      "Saved best model with min rewards 6297.38\n",
      "Saved best model with min rewards 6299.21\n",
      "Num timesteps 520000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -468.6423 Q1/Q2/Critic 9.4194/8.5146/17.93 \n",
      "Last 20 training episodes: mean/median reward 6287.2/6278.9, min/max reward 6020.0/6465.5\n",
      "Num timesteps 530000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -460.4731 Q1/Q2/Critic 10.6927/12.1604/22.85 \n",
      "Last 20 training episodes: mean/median reward 6288.3/6282.2, min/max reward 6020.0/6465.5\n",
      "Saved best model with min rewards 6300.66\n",
      "Num timesteps 540000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -468.0967 Q1/Q2/Critic 10.8016/10.9810/21.78 \n",
      "Last 20 training episodes: mean/median reward 6300.7/6316.5, min/max reward 6134.1/6427.0\n",
      "Saved best model with min rewards 6304.15\n",
      "Saved best model with min rewards 6304.72\n",
      "Saved best model with min rewards 6314.49\n",
      "Saved best model with min rewards 6321.67\n",
      "Saved best model with min rewards 6335.72\n",
      "Saved best model with min rewards 6339.45\n",
      "Saved best model with min rewards 6341.03\n",
      "Num timesteps 550000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -477.0114 Q1/Q2/Critic 7.8340/7.9499/15.78 \n",
      "Last 20 training episodes: mean/median reward 6338.4/6349.8, min/max reward 6134.1/6496.9\n",
      "Saved best model with min rewards 6342.85\n",
      "Saved best model with min rewards 6350.41\n",
      "Saved best model with min rewards 6366.45\n",
      "Saved best model with min rewards 6368.62\n",
      "Saved best model with min rewards 6377.60\n",
      "Saved best model with min rewards 6382.38\n",
      "Num timesteps 560000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -477.9553 Q1/Q2/Critic 8.1978/6.4788/14.68 \n",
      "Last 20 training episodes: mean/median reward 6381.1/6381.7, min/max reward 6273.1/6496.9\n",
      "Saved best model with min rewards 6382.48\n",
      "Saved best model with min rewards 6384.57\n",
      "Saved best model with min rewards 6387.43\n",
      "Saved best model with min rewards 6394.95\n",
      "Num timesteps 570000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -483.5956 Q1/Q2/Critic 8.8590/8.5919/17.45 \n",
      "Last 20 training episodes: mean/median reward 6395.0/6404.9, min/max reward 6283.5/6495.7\n",
      "Num timesteps 580000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -477.6689 Q1/Q2/Critic 95.9657/93.1512/189.1 \n",
      "Last 20 training episodes: mean/median reward 6366.4/6394.6, min/max reward 6092.4/6495.7\n",
      "Num timesteps 590000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -489.4556 Q1/Q2/Critic 9.2243/8.1946/17.42 \n",
      "Last 20 training episodes: mean/median reward 6350.4/6386.6, min/max reward 6092.4/6455.6\n",
      "Saved best model with min rewards 6403.30\n",
      "Saved best model with min rewards 6414.77\n",
      "Num timesteps 600000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -487.9207 Q1/Q2/Critic 8.3857/8.2888/16.67 \n",
      "Last 20 training episodes: mean/median reward 6414.8/6432.4, min/max reward 6155.9/6612.4\n",
      "Saved best model with min rewards 6417.74\n",
      "Saved best model with min rewards 6419.25\n",
      "Saved best model with min rewards 6419.99\n",
      "Saved best model with min rewards 6425.71\n",
      "Saved best model with min rewards 6433.55\n",
      "Saved best model with min rewards 6453.00\n",
      "Saved best model with min rewards 6455.11\n",
      "Saved best model with min rewards 6478.32\n",
      "Num timesteps 610000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -482.6479 Q1/Q2/Critic 10.8687/10.1092/20.98 \n",
      "Last 20 training episodes: mean/median reward 6471.7/6470.0, min/max reward 6245.6/6758.9\n",
      "Num timesteps 620000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -493.8465 Q1/Q2/Critic 12.6830/12.3278/25.01 \n",
      "Last 20 training episodes: mean/median reward 6371.6/6523.2, min/max reward 3593.7/6758.9\n",
      "Num timesteps 630000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -491.6685 Q1/Q2/Critic 12.0178/14.0631/26.08 \n",
      "Last 20 training episodes: mean/median reward 6403.1/6547.6, min/max reward 3593.7/6742.5\n",
      "Saved best model with min rewards 6560.95\n",
      "Saved best model with min rewards 6563.10\n",
      "Saved best model with min rewards 6563.88\n",
      "Saved best model with min rewards 6567.58\n",
      "Saved best model with min rewards 6574.96\n",
      "Saved best model with min rewards 6581.62\n",
      "Num timesteps 640000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -503.3138 Q1/Q2/Critic 7.9262/6.8094/14.74 \n",
      "Last 20 training episodes: mean/median reward 6581.6/6559.7, min/max reward 6436.2/6742.5\n",
      "Saved best model with min rewards 6585.13\n",
      "Saved best model with min rewards 6585.88\n",
      "Saved best model with min rewards 6596.51\n",
      "Saved best model with min rewards 6602.62\n",
      "Num timesteps 650000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -495.7286 Q1/Q2/Critic 128.6520/123.7040/252.4 \n",
      "Last 20 training episodes: mean/median reward 6599.4/6589.5, min/max reward 6436.2/6758.0\n",
      "Saved best model with min rewards 6608.28\n",
      "Num timesteps 660000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -500.2440 Q1/Q2/Critic 104.8719/104.2196/209.1 \n",
      "Last 20 training episodes: mean/median reward 6574.7/6573.8, min/max reward 6459.4/6758.0\n",
      "Num timesteps 670000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -509.8228 Q1/Q2/Critic 7.7296/8.7683/16.5 \n",
      "Last 20 training episodes: mean/median reward 6574.0/6565.2, min/max reward 6459.4/6821.3\n",
      "Num timesteps 680000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -501.5906 Q1/Q2/Critic 14.0610/14.1508/28.21 \n",
      "Last 20 training episodes: mean/median reward 6577.7/6568.2, min/max reward 6377.5/6821.3\n",
      "Num timesteps 690000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -508.0754 Q1/Q2/Critic 8.8218/6.9519/15.77 \n",
      "Last 20 training episodes: mean/median reward 6555.0/6559.7, min/max reward 6377.5/6744.2\n",
      "Num timesteps 700000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -506.3748 Q1/Q2/Critic 9.7316/10.1327/19.86 \n",
      "Last 20 training episodes: mean/median reward 6569.6/6570.5, min/max reward 6306.3/6755.1\n",
      "Saved best model with min rewards 6608.52\n",
      "Saved best model with min rewards 6620.40\n",
      "Saved best model with min rewards 6629.02\n",
      "Saved best model with min rewards 6632.61\n",
      "Num timesteps 710000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -516.6447 Q1/Q2/Critic 10.2497/8.6526/18.9 \n",
      "Last 20 training episodes: mean/median reward 6632.6/6670.9, min/max reward 6306.3/6809.8\n",
      "Saved best model with min rewards 6643.19\n",
      "Saved best model with min rewards 6645.70\n",
      "Saved best model with min rewards 6649.14\n",
      "Saved best model with min rewards 6674.24\n",
      "Saved best model with min rewards 6682.70\n",
      "Saved best model with min rewards 6687.17\n",
      "Num timesteps 720000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -502.0632 Q1/Q2/Critic 10.7645/10.0088/20.77 \n",
      "Last 20 training episodes: mean/median reward 6687.2/6700.1, min/max reward 6474.0/6845.2\n",
      "Saved best model with min rewards 6689.97\n",
      "Saved best model with min rewards 6702.17\n",
      "Saved best model with min rewards 6706.29\n",
      "Num timesteps 730000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -517.0393 Q1/Q2/Critic 147.1982/144.7396/291.9 \n",
      "Last 20 training episodes: mean/median reward 6670.4/6678.5, min/max reward 6472.1/6845.2\n",
      "Num timesteps 740000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -505.3485 Q1/Q2/Critic 8.8342/8.9828/17.82 \n",
      "Last 20 training episodes: mean/median reward 6670.4/6697.1, min/max reward 6472.1/6803.2\n",
      "Saved best model with min rewards 6712.34\n",
      "Num timesteps 750000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -512.0507 Q1/Q2/Critic 69.1390/66.1685/135.3 \n",
      "Last 20 training episodes: mean/median reward 6712.3/6726.8, min/max reward 6551.4/6872.5\n",
      "Saved best model with min rewards 6722.63\n",
      "Saved best model with min rewards 6729.72\n",
      "Saved best model with min rewards 6733.40\n",
      "Saved best model with min rewards 6733.90\n",
      "Saved best model with min rewards 6738.71\n",
      "Num timesteps 760000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -513.8755 Q1/Q2/Critic 10.5407/9.7704/20.31 \n",
      "Last 20 training episodes: mean/median reward 6738.7/6745.6, min/max reward 6551.4/6872.5\n",
      "Num timesteps 770000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -511.5540 Q1/Q2/Critic 11.0815/11.3854/22.47 \n",
      "Last 20 training episodes: mean/median reward 6715.4/6712.3, min/max reward 6602.5/6844.5\n",
      "Num timesteps 780000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -520.6519 Q1/Q2/Critic 99.4604/100.6948/200.2 \n",
      "Last 20 training episodes: mean/median reward 6704.9/6703.4, min/max reward 6578.9/6855.2\n",
      "Saved best model with min rewards 6740.91\n",
      "Saved best model with min rewards 6741.45\n",
      "Saved best model with min rewards 6742.56\n",
      "Num timesteps 790000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -515.7042 Q1/Q2/Critic 91.6689/92.1355/183.8 \n",
      "Last 20 training episodes: mean/median reward 6742.6/6768.2, min/max reward 6578.9/6855.3\n",
      "Saved best model with min rewards 6749.12\n",
      "Saved best model with min rewards 6754.56\n",
      "Saved best model with min rewards 6762.67\n",
      "Saved best model with min rewards 6766.03\n",
      "Saved best model with min rewards 6767.30\n",
      "Saved best model with min rewards 6786.02\n",
      "Saved best model with min rewards 6787.77\n",
      "Saved best model with min rewards 6798.68\n",
      "Num timesteps 800000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -521.7915 Q1/Q2/Critic 10.7846/11.8790/22.66 \n",
      "Last 20 training episodes: mean/median reward 6798.7/6796.2, min/max reward 6601.4/6975.0\n",
      "Saved best model with min rewards 6804.15\n",
      "Saved best model with min rewards 6810.54\n",
      "Saved best model with min rewards 6813.43\n",
      "Saved best model with min rewards 6822.13\n",
      "Saved best model with min rewards 6823.89\n",
      "Saved best model with min rewards 6828.86\n",
      "Num timesteps 810000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -519.1066 Q1/Q2/Critic 11.9828/10.6209/22.6 \n",
      "Last 20 training episodes: mean/median reward 6824.5/6836.8, min/max reward 6656.1/6975.0\n",
      "Saved best model with min rewards 6829.79\n",
      "Saved best model with min rewards 6832.87\n",
      "Num timesteps 820000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -522.6227 Q1/Q2/Critic 210.3363/211.5603/421.9 \n",
      "Last 20 training episodes: mean/median reward 6799.1/6806.3, min/max reward 6656.1/6950.8\n",
      "Num timesteps 830000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -532.5582 Q1/Q2/Critic 7.1633/7.3523/14.52 \n",
      "Last 20 training episodes: mean/median reward 6809.2/6812.4, min/max reward 6669.9/6933.9\n",
      "Saved best model with min rewards 6840.80\n",
      "Saved best model with min rewards 6852.00\n",
      "Num timesteps 840000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -525.2988 Q1/Q2/Critic 9.2966/9.5389/18.84 \n",
      "Last 20 training episodes: mean/median reward 6852.0/6862.4, min/max reward 6724.3/6973.3\n",
      "Saved best model with min rewards 6858.27\n",
      "Saved best model with min rewards 6872.23\n",
      "Saved best model with min rewards 6881.87\n",
      "Saved best model with min rewards 6892.42\n",
      "Saved best model with min rewards 6893.65\n",
      "Num timesteps 850000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -535.1222 Q1/Q2/Critic 12.1021/11.1463/23.25 \n",
      "Last 20 training episodes: mean/median reward 6893.6/6904.5, min/max reward 6744.7/7052.5\n",
      "Saved best model with min rewards 6894.51\n",
      "Num timesteps 860000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -530.7597 Q1/Q2/Critic 7.5760/7.3105/14.89 \n",
      "Last 20 training episodes: mean/median reward 6894.5/6923.3, min/max reward 6682.8/7052.5\n",
      "Saved best model with min rewards 6898.07\n",
      "Saved best model with min rewards 6899.50\n",
      "Saved best model with min rewards 6908.98\n",
      "Num timesteps 870000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -528.8390 Q1/Q2/Critic 11.0502/9.5727/20.62 \n",
      "Last 20 training episodes: mean/median reward 6901.6/6925.9, min/max reward 6682.8/7089.4\n",
      "Saved best model with min rewards 6911.28\n",
      "Saved best model with min rewards 6919.86\n",
      "Saved best model with min rewards 6922.16\n",
      "Saved best model with min rewards 6924.01\n",
      "Saved best model with min rewards 6933.47\n",
      "Saved best model with min rewards 6944.13\n",
      "Saved best model with min rewards 6946.49\n",
      "Num timesteps 880000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -537.5079 Q1/Q2/Critic 14.3231/14.3424/28.67 \n",
      "Last 20 training episodes: mean/median reward 6946.5/6963.5, min/max reward 6790.2/7089.4\n",
      "Saved best model with min rewards 6954.00\n",
      "Saved best model with min rewards 6959.18\n",
      "Saved best model with min rewards 6966.51\n",
      "Saved best model with min rewards 6974.24\n",
      "Saved best model with min rewards 6975.88\n",
      "Num timesteps 890000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -535.0629 Q1/Q2/Critic 11.5151/9.9837/21.5 \n",
      "Last 20 training episodes: mean/median reward 6975.9/6980.7, min/max reward 6790.2/7123.1\n",
      "Saved best model with min rewards 6985.42\n",
      "Saved best model with min rewards 6986.31\n",
      "Num timesteps 900000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -548.5103 Q1/Q2/Critic 190.6060/185.9828/376.6 \n",
      "Last 20 training episodes: mean/median reward 6973.0/6969.0, min/max reward 6800.6/7123.1\n",
      "Saved best model with min rewards 6996.71\n",
      "Saved best model with min rewards 6998.82\n",
      "Num timesteps 910000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -540.2521 Q1/Q2/Critic 8.3844/8.6540/17.04 \n",
      "Last 20 training episodes: mean/median reward 6994.4/6999.3, min/max reward 6800.6/7168.1\n",
      "Saved best model with min rewards 7001.19\n",
      "Saved best model with min rewards 7015.13\n",
      "Saved best model with min rewards 7016.07\n",
      "Saved best model with min rewards 7026.41\n",
      "Saved best model with min rewards 7031.19\n",
      "Saved best model with min rewards 7037.34\n",
      "Saved best model with min rewards 7039.34\n",
      "Saved best model with min rewards 7057.58\n",
      "Num timesteps 920000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -538.0266 Q1/Q2/Critic 8.3675/8.0904/16.46 \n",
      "Last 20 training episodes: mean/median reward 7057.6/7038.3, min/max reward 6935.4/7233.2\n",
      "Saved best model with min rewards 7065.54\n",
      "Saved best model with min rewards 7081.63\n",
      "Saved best model with min rewards 7092.25\n",
      "Saved best model with min rewards 7100.77\n",
      "Num timesteps 930000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -539.2156 Q1/Q2/Critic 6.7118/7.5979/14.31 \n",
      "Last 20 training episodes: mean/median reward 7085.4/7070.7, min/max reward 6903.4/7309.1\n",
      "Saved best model with min rewards 7108.44\n",
      "Saved best model with min rewards 7118.62\n",
      "Num timesteps 940000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -543.6531 Q1/Q2/Critic 7.6720/8.5833/16.26 \n",
      "Last 20 training episodes: mean/median reward 7117.0/7128.5, min/max reward 6903.4/7309.1\n",
      "Saved best model with min rewards 7122.23\n",
      "Saved best model with min rewards 7131.33\n",
      "Num timesteps 950000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -544.0359 Q1/Q2/Critic 9.8698/9.3590/19.23 \n",
      "Last 20 training episodes: mean/median reward 7130.0/7160.0, min/max reward 6850.2/7243.4\n",
      "Saved best model with min rewards 7132.75\n",
      "Saved best model with min rewards 7134.56\n",
      "Saved best model with min rewards 7135.12\n",
      "Num timesteps 960000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -539.3456 Q1/Q2/Critic 47.5901/53.1223/100.7 \n",
      "Last 20 training episodes: mean/median reward 7129.1/7125.9, min/max reward 6850.2/7316.7\n",
      "Saved best model with min rewards 7146.48\n",
      "Saved best model with min rewards 7150.39\n",
      "Saved best model with min rewards 7150.99\n",
      "Num timesteps 970000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -545.7549 Q1/Q2/Critic 10.6980/13.4151/24.11 \n",
      "Last 20 training episodes: mean/median reward 7143.9/7153.6, min/max reward 7020.2/7316.7\n",
      "Saved best model with min rewards 7154.29\n",
      "Saved best model with min rewards 7165.25\n",
      "Num timesteps 980000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -550.3741 Q1/Q2/Critic 13.3739/15.2068/28.58 \n",
      "Last 20 training episodes: mean/median reward 7154.2/7174.5, min/max reward 6395.7/7440.2\n",
      "Saved best model with min rewards 7172.77\n",
      "Saved best model with min rewards 7178.56\n",
      "Num timesteps 990000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -543.1750 Q1/Q2/Critic 94.6130/94.8717/189.5 \n",
      "Last 20 training episodes: mean/median reward 7178.6/7216.8, min/max reward 6395.7/7440.2\n",
      "Saved best model with min rewards 7218.10\n",
      "Saved best model with min rewards 7221.00\n",
      "Saved best model with min rewards 7224.76\n",
      "Saved best model with min rewards 7227.46\n",
      "Saved best model with min rewards 7232.24\n",
      "Num timesteps 1000000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -550.7991 Q1/Q2/Critic 12.1128/13.0267/25.14 \n",
      "Last 20 training episodes: mean/median reward 7232.2/7256.7, min/max reward 7028.1/7330.6\n",
      "Saving last...\n"
     ]
    }
   ],
   "source": [
    "from helpers.envs import make_sync_vec, AutoresetMode\n",
    "\n",
    "num_envs = 1\n",
    "env_id = 'HalfCheetah-v5'\n",
    "\n",
    "envs = make_sync_vec(env_id, \n",
    "                    num_envs=num_envs, \n",
    "                    wrappers=(gym.wrappers.RecordEpisodeStatistics,),\n",
    "                    autoreset_mode=AutoresetMode.SAME_STEP)\n",
    "\n",
    "action_size = envs.single_action_space.shape[0]\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "# param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.05, desired_action_stddev=0.2)\n",
    "normal_noise = NormalActionNoise(action_size, 0.1)\n",
    "\n",
    "\n",
    "agent = TD3Agent(envs,  \n",
    "            learning_starts=25000,\n",
    "\n",
    "            mini_batch_size=256,\n",
    "            gamma=0.99,  \n",
    "            tau=0.005,\n",
    "            actor_lr=3e-4,\n",
    "            critic_lr=3e-4,\n",
    "            action_noise=normal_noise,\n",
    "            target_policy_noise=0.2,\n",
    "            target_noise_clip=0.5,\n",
    "            policy_delay=2,\n",
    "            layer_norm=False,\n",
    "            device=DEVICE,\n",
    "            reward_to_achieve=2500)\n",
    "\n",
    "agent.train(total_timesteps=1e6, eval_frequency=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Example - Ant-v5\n",
    "\n",
    "Setup the envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.2 0.5\n",
      "0.1\n",
      "----------------------------------------------------------------------------\n",
      "| Hyperparams                    | Values                                  |\n",
      "----------------------------------------------------------------------------\n",
      "| actor_lr                       | 0.0003                                  |\n",
      "| critic_lr                      | 0.0003                                  |\n",
      "| gamma                          | 0.99                                    |\n",
      "| tau                            | 0.005                                   |\n",
      "| buffer_size                    | 1000000.0                               |\n",
      "| mini_batch_size                | 256                                     |\n",
      "| policy_delay                   | 2                                       |\n",
      "| target_policy_noise            | 0.2                                     |\n",
      "| target_noise_clip              | 0.5                                     |\n",
      "| action_noise                   | 0.1                                     |\n",
      "----------------------------------------------------------------------------\n",
      "Num timesteps 10000/1000000.0 Mean Length 77.1\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 20 training episodes: mean/median reward -38.6/-23.5, min/max reward -180.2/6.0\n",
      "Num timesteps 20000/1000000.0 Mean Length 139.8\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 20 training episodes: mean/median reward -45.3/-20.0, min/max reward -462.8/19.7\n",
      "Num timesteps 30000/1000000.0 Mean Length 422.1\n",
      "Loss Actor -6.3460 Q1/Q2/Critic 1.6650/1.7736/3.439 \n",
      "Last 20 training episodes: mean/median reward 47.8/-16.1, min/max reward -292.8/633.3\n",
      "Num timesteps 40000/1000000.0 Mean Length 635.0\n",
      "Loss Actor -20.1158 Q1/Q2/Critic 1.4965/1.3933/2.89 \n",
      "Last 20 training episodes: mean/median reward 361.9/361.8, min/max reward -0.9/880.3\n",
      "Num timesteps 50000/1000000.0 Mean Length 469.1\n",
      "Loss Actor -28.0499 Q1/Q2/Critic 1.7477/1.8092/3.557 \n",
      "Last 20 training episodes: mean/median reward 206.5/212.6, min/max reward 12.4/545.2\n",
      "Num timesteps 60000/1000000.0 Mean Length 288.9\n",
      "Loss Actor -31.2436 Q1/Q2/Critic 2.4860/1.9224/4.408 \n",
      "Last 20 training episodes: mean/median reward 138.4/108.9, min/max reward 1.5/515.0\n",
      "Num timesteps 70000/1000000.0 Mean Length 523.6\n",
      "Loss Actor -37.7820 Q1/Q2/Critic 2.4438/2.1541/4.598 \n",
      "Last 20 training episodes: mean/median reward 296.8/277.4, min/max reward 16.8/737.6\n",
      "Num timesteps 80000/1000000.0 Mean Length 588.4\n",
      "Loss Actor -40.5244 Q1/Q2/Critic 3.9873/3.5920/7.579 \n",
      "Last 20 training episodes: mean/median reward 353.4/371.0, min/max reward 7.8/737.6\n",
      "Num timesteps 90000/1000000.0 Mean Length 415.7\n",
      "Loss Actor -42.9899 Q1/Q2/Critic 3.2202/3.3511/6.571 \n",
      "Last 20 training episodes: mean/median reward 316.2/206.5, min/max reward 11.2/837.9\n",
      "Num timesteps 100000/1000000.0 Mean Length 352.8\n",
      "Loss Actor -48.0137 Q1/Q2/Critic 3.5429/2.2076/5.751 \n",
      "Last 20 training episodes: mean/median reward 284.9/196.5, min/max reward 8.8/849.0\n",
      "Num timesteps 110000/1000000.0 Mean Length 469.2\n",
      "Loss Actor -51.3279 Q1/Q2/Critic 2.1269/2.0820/4.209 \n",
      "Last 20 training episodes: mean/median reward 428.1/346.8, min/max reward 24.4/1073.6\n",
      "Num timesteps 120000/1000000.0 Mean Length 607.4\n",
      "Loss Actor -53.4935 Q1/Q2/Critic 2.8184/2.9919/5.81 \n",
      "Last 20 training episodes: mean/median reward 538.3/649.9, min/max reward 58.6/859.0\n",
      "Num timesteps 130000/1000000.0 Mean Length 467.4\n",
      "Loss Actor -57.0424 Q1/Q2/Critic 3.0213/3.2822/6.303 \n",
      "Last 20 training episodes: mean/median reward 428.0/368.1, min/max reward 13.7/1041.1\n",
      "Num timesteps 140000/1000000.0 Mean Length 613.1\n",
      "Loss Actor -62.3448 Q1/Q2/Critic 3.0318/2.6007/5.633 \n",
      "Last 20 training episodes: mean/median reward 551.5/649.3, min/max reward 37.8/1106.6\n",
      "Num timesteps 150000/1000000.0 Mean Length 490.1\n",
      "Loss Actor -64.5879 Q1/Q2/Critic 14.6372/14.7431/29.38 \n",
      "Last 20 training episodes: mean/median reward 535.5/454.0, min/max reward 21.9/1612.0\n",
      "Num timesteps 160000/1000000.0 Mean Length 560.1\n",
      "Loss Actor -66.4437 Q1/Q2/Critic 3.4084/3.7383/7.147 \n",
      "Last 20 training episodes: mean/median reward 529.4/506.7, min/max reward 21.9/1139.3\n",
      "Num timesteps 170000/1000000.0 Mean Length 456.1\n",
      "Loss Actor -65.4250 Q1/Q2/Critic 4.4576/5.1292/9.587 \n",
      "Last 20 training episodes: mean/median reward 480.7/323.7, min/max reward 31.6/1387.3\n",
      "Num timesteps 180000/1000000.0 Mean Length 592.7\n",
      "Loss Actor -70.3163 Q1/Q2/Critic 2.3462/2.2683/4.615 \n",
      "Last 20 training episodes: mean/median reward 717.0/738.2, min/max reward 39.2/1653.5\n",
      "Num timesteps 190000/1000000.0 Mean Length 593.2\n",
      "Loss Actor -74.0529 Q1/Q2/Critic 3.2326/4.1950/7.428 \n",
      "Last 20 training episodes: mean/median reward 603.6/573.6, min/max reward 115.3/1137.1\n",
      "Num timesteps 200000/1000000.0 Mean Length 478.4\n",
      "Loss Actor -74.7166 Q1/Q2/Critic 4.6465/4.0108/8.657 \n",
      "Last 20 training episodes: mean/median reward 529.8/473.3, min/max reward 74.0/1269.8\n",
      "Num timesteps 210000/1000000.0 Mean Length 618.5\n",
      "Loss Actor -73.1673 Q1/Q2/Critic 4.6224/4.6901/9.312 \n",
      "Last 20 training episodes: mean/median reward 720.9/814.7, min/max reward 18.8/1630.4\n",
      "Num timesteps 220000/1000000.0 Mean Length 755.6\n",
      "Loss Actor -78.6451 Q1/Q2/Critic 4.5215/4.9579/9.479 \n",
      "Last 20 training episodes: mean/median reward 932.3/915.3, min/max reward 18.8/1838.2\n",
      "Num timesteps 230000/1000000.0 Mean Length 684.7\n",
      "Loss Actor -77.5999 Q1/Q2/Critic 4.1878/5.4974/9.685 \n",
      "Last 20 training episodes: mean/median reward 792.9/727.1, min/max reward 53.5/1871.4\n",
      "Num timesteps 240000/1000000.0 Mean Length 718.0\n",
      "Loss Actor -76.5986 Q1/Q2/Critic 4.5980/6.2646/10.86 \n",
      "Last 20 training episodes: mean/median reward 788.3/777.6, min/max reward 153.8/1871.4\n",
      "Num timesteps 250000/1000000.0 Mean Length 679.2\n",
      "Loss Actor -80.5478 Q1/Q2/Critic 4.6632/4.2173/8.88 \n",
      "Last 20 training episodes: mean/median reward 813.7/809.0, min/max reward 20.2/1915.3\n",
      "Num timesteps 260000/1000000.0 Mean Length 543.9\n",
      "Loss Actor -85.7638 Q1/Q2/Critic 4.4877/4.7892/9.277 \n",
      "Last 20 training episodes: mean/median reward 802.9/726.9, min/max reward 50.6/1855.1\n",
      "Num timesteps 270000/1000000.0 Mean Length 665.2\n",
      "Loss Actor -86.0169 Q1/Q2/Critic 4.1534/4.3990/8.552 \n",
      "Last 20 training episodes: mean/median reward 914.9/850.5, min/max reward 17.4/2332.6\n",
      "Num timesteps 280000/1000000.0 Mean Length 762.2\n",
      "Loss Actor -82.3068 Q1/Q2/Critic 4.3997/4.0760/8.476 \n",
      "Last 20 training episodes: mean/median reward 1159.0/1154.9, min/max reward 74.7/2339.5\n",
      "Num timesteps 290000/1000000.0 Mean Length 731.9\n",
      "Loss Actor -82.7322 Q1/Q2/Critic 4.6288/7.2903/11.92 \n",
      "Last 20 training episodes: mean/median reward 1192.8/1199.1, min/max reward 74.7/2339.5\n",
      "Num timesteps 300000/1000000.0 Mean Length 687.5\n",
      "Loss Actor -83.9641 Q1/Q2/Critic 5.9823/8.0521/14.03 \n",
      "Last 20 training episodes: mean/median reward 1155.5/1211.0, min/max reward 15.0/2382.1\n",
      "Num timesteps 310000/1000000.0 Mean Length 717.6\n",
      "Loss Actor -89.9419 Q1/Q2/Critic 5.9439/5.1751/11.12 \n",
      "Last 20 training episodes: mean/median reward 1050.0/1021.5, min/max reward 15.0/2400.6\n",
      "Num timesteps 320000/1000000.0 Mean Length 725.2\n",
      "Loss Actor -88.6813 Q1/Q2/Critic 4.8867/4.1103/8.997 \n",
      "Last 20 training episodes: mean/median reward 1194.0/952.2, min/max reward 173.2/2431.5\n",
      "Num timesteps 330000/1000000.0 Mean Length 820.0\n",
      "Loss Actor -94.4145 Q1/Q2/Critic 5.9533/6.0940/12.05 \n",
      "Last 20 training episodes: mean/median reward 1539.5/1425.1, min/max reward 32.2/2535.8\n",
      "Num timesteps 340000/1000000.0 Mean Length 694.6\n",
      "Loss Actor -92.7231 Q1/Q2/Critic 6.8035/5.6810/12.48 \n",
      "Last 20 training episodes: mean/median reward 1268.8/1108.4, min/max reward 32.2/2527.6\n",
      "Num timesteps 350000/1000000.0 Mean Length 740.9\n",
      "Loss Actor -94.4334 Q1/Q2/Critic 6.7411/6.5318/13.27 \n",
      "Last 20 training episodes: mean/median reward 1123.5/1108.4, min/max reward 265.2/2684.6\n",
      "Num timesteps 360000/1000000.0 Mean Length 792.9\n",
      "Loss Actor -98.4869 Q1/Q2/Critic 6.4188/6.5835/13.0 \n",
      "Last 20 training episodes: mean/median reward 1370.5/1259.1, min/max reward 265.2/2684.6\n",
      "Num timesteps 370000/1000000.0 Mean Length 757.3\n",
      "Loss Actor -100.3399 Q1/Q2/Critic 6.3201/5.9145/12.23 \n",
      "Last 20 training episodes: mean/median reward 1354.7/1003.0, min/max reward 201.7/2611.2\n",
      "Num timesteps 380000/1000000.0 Mean Length 600.2\n",
      "Loss Actor -97.5276 Q1/Q2/Critic 8.5111/8.4591/16.97 \n",
      "Last 20 training episodes: mean/median reward 1392.6/1198.6, min/max reward 20.6/2817.9\n",
      "Num timesteps 390000/1000000.0 Mean Length 654.9\n",
      "Loss Actor -103.6230 Q1/Q2/Critic 8.4872/6.9264/15.41 \n",
      "Last 20 training episodes: mean/median reward 1328.9/1326.6, min/max reward 70.4/3051.8\n",
      "Num timesteps 400000/1000000.0 Mean Length 607.5\n",
      "Loss Actor -104.3659 Q1/Q2/Critic 11.3451/10.4669/21.81 \n",
      "Last 20 training episodes: mean/median reward 1245.4/1165.9, min/max reward 20.1/3144.7\n",
      "Num timesteps 410000/1000000.0 Mean Length 613.7\n",
      "Loss Actor -109.4699 Q1/Q2/Critic 8.1207/9.2738/17.39 \n",
      "Last 20 training episodes: mean/median reward 1447.9/1447.5, min/max reward 20.1/3093.3\n",
      "Num timesteps 420000/1000000.0 Mean Length 651.4\n",
      "Loss Actor -115.6520 Q1/Q2/Critic 28.0792/26.3632/54.44 \n",
      "Last 20 training episodes: mean/median reward 1615.1/1393.8, min/max reward 109.5/3356.0\n",
      "Num timesteps 430000/1000000.0 Mean Length 710.2\n",
      "Loss Actor -118.6688 Q1/Q2/Critic 8.3421/7.1700/15.51 \n",
      "Last 20 training episodes: mean/median reward 2078.6/2264.7, min/max reward 332.3/3356.0\n",
      "Num timesteps 440000/1000000.0 Mean Length 553.1\n",
      "Loss Actor -117.9720 Q1/Q2/Critic 13.3897/13.5464/26.94 \n",
      "Last 20 training episodes: mean/median reward 1576.3/1170.4, min/max reward 234.4/3427.2\n",
      "Num timesteps 450000/1000000.0 Mean Length 677.5\n",
      "Loss Actor -115.3594 Q1/Q2/Critic 9.5266/10.4895/20.02 \n",
      "Last 20 training episodes: mean/median reward 1545.7/1267.8, min/max reward 15.2/3433.8\n",
      "Num timesteps 460000/1000000.0 Mean Length 658.4\n",
      "Loss Actor -111.9013 Q1/Q2/Critic 11.1270/10.5170/21.64 \n",
      "Last 20 training episodes: mean/median reward 1641.6/1447.5, min/max reward 15.2/3310.7\n",
      "Num timesteps 470000/1000000.0 Mean Length 685.6\n",
      "Loss Actor -124.2573 Q1/Q2/Critic 16.1097/11.7537/27.86 \n",
      "Last 20 training episodes: mean/median reward 1923.3/1903.6, min/max reward 279.2/3690.6\n",
      "Num timesteps 480000/1000000.0 Mean Length 755.4\n",
      "Loss Actor -125.9238 Q1/Q2/Critic 10.0116/14.6346/24.65 \n",
      "Last 20 training episodes: mean/median reward 2162.5/1972.2, min/max reward 226.8/3485.4\n",
      "Num timesteps 490000/1000000.0 Mean Length 672.0\n",
      "Loss Actor -131.5246 Q1/Q2/Critic 21.1483/22.9249/44.07 \n",
      "Last 20 training episodes: mean/median reward 1941.6/1716.4, min/max reward 85.4/3555.6\n",
      "Num timesteps 500000/1000000.0 Mean Length 697.9\n",
      "Loss Actor -130.5232 Q1/Q2/Critic 15.5522/12.5778/28.13 \n",
      "Last 20 training episodes: mean/median reward 2181.3/2063.0, min/max reward 320.8/3577.1\n",
      "Num timesteps 510000/1000000.0 Mean Length 715.5\n",
      "Loss Actor -132.6817 Q1/Q2/Critic 29.9595/52.6223/82.58 \n",
      "Last 20 training episodes: mean/median reward 2413.3/2900.6, min/max reward -8.4/3892.9\n",
      "Saved best model with min rewards 2526.51\n",
      "Saved best model with min rewards 2555.46\n",
      "Saved best model with min rewards 2731.04\n",
      "Num timesteps 520000/1000000.0 Mean Length 811.9\n",
      "Loss Actor -134.3681 Q1/Q2/Critic 14.1495/18.5610/32.71 \n",
      "Last 20 training episodes: mean/median reward 2606.9/2944.1, min/max reward -8.4/3892.9\n",
      "Num timesteps 530000/1000000.0 Mean Length 818.8\n",
      "Loss Actor -140.2024 Q1/Q2/Critic 24.6642/19.3307/43.99 \n",
      "Last 20 training episodes: mean/median reward 2355.0/2815.3, min/max reward 17.7/3892.2\n",
      "Num timesteps 540000/1000000.0 Mean Length 685.0\n",
      "Loss Actor -145.8983 Q1/Q2/Critic 13.2412/15.3231/28.56 \n",
      "Last 20 training episodes: mean/median reward 2020.9/1992.6, min/max reward 46.3/3896.5\n",
      "Num timesteps 550000/1000000.0 Mean Length 690.1\n",
      "Loss Actor -156.1463 Q1/Q2/Critic 18.1264/18.2168/36.34 \n",
      "Last 20 training episodes: mean/median reward 2129.4/2168.4, min/max reward 46.3/3953.2\n",
      "Num timesteps 560000/1000000.0 Mean Length 805.1\n",
      "Loss Actor -163.2760 Q1/Q2/Critic 43.1713/23.2674/66.44 \n",
      "Last 20 training episodes: mean/median reward 2692.2/3197.8, min/max reward 325.0/4186.9\n",
      "Saved best model with min rewards 2754.43\n",
      "Saved best model with min rewards 2772.85\n",
      "Saved best model with min rewards 2795.37\n",
      "Saved best model with min rewards 2802.62\n",
      "Saved best model with min rewards 2836.69\n",
      "Saved best model with min rewards 2962.85\n",
      "Saved best model with min rewards 3042.19\n",
      "Num timesteps 570000/1000000.0 Mean Length 885.0\n",
      "Loss Actor -150.6632 Q1/Q2/Critic 24.3126/20.6771/44.99 \n",
      "Last 20 training episodes: mean/median reward 2912.0/3657.9, min/max reward 648.6/4052.2\n",
      "Saved best model with min rewards 3084.88\n",
      "Saved best model with min rewards 3085.64\n",
      "Saved best model with min rewards 3110.50\n",
      "Saved best model with min rewards 3118.92\n",
      "Num timesteps 580000/1000000.0 Mean Length 892.9\n",
      "Loss Actor -154.3763 Q1/Q2/Critic 13.5848/14.6693/28.25 \n",
      "Last 20 training episodes: mean/median reward 3101.3/3708.9, min/max reward 829.3/4345.1\n",
      "Num timesteps 590000/1000000.0 Mean Length 850.8\n",
      "Loss Actor -152.1374 Q1/Q2/Critic 98.4364/93.7116/192.1 \n",
      "Last 20 training episodes: mean/median reward 2858.4/3631.0, min/max reward 41.9/4281.5\n",
      "Num timesteps 600000/1000000.0 Mean Length 767.9\n",
      "Loss Actor -157.8860 Q1/Q2/Critic 20.1134/20.2581/40.37 \n",
      "Last 20 training episodes: mean/median reward 2559.1/3103.7, min/max reward 41.9/4281.5\n",
      "Saved best model with min rewards 3132.51\n",
      "Num timesteps 610000/1000000.0 Mean Length 845.1\n",
      "Loss Actor -160.0690 Q1/Q2/Critic 29.2767/24.1223/53.4 \n",
      "Last 20 training episodes: mean/median reward 3132.5/3936.7, min/max reward 31.4/4251.5\n",
      "Saved best model with min rewards 3157.06\n",
      "Saved best model with min rewards 3322.42\n",
      "Saved best model with min rewards 3337.67\n",
      "Saved best model with min rewards 3366.22\n",
      "Num timesteps 620000/1000000.0 Mean Length 640.8\n",
      "Loss Actor -161.0343 Q1/Q2/Critic 21.1662/20.6878/41.85 \n",
      "Last 20 training episodes: mean/median reward 2414.6/3005.8, min/max reward 16.2/4532.1\n",
      "Num timesteps 630000/1000000.0 Mean Length 709.5\n",
      "Loss Actor -158.4974 Q1/Q2/Critic 16.1521/17.7136/33.87 \n",
      "Last 20 training episodes: mean/median reward 2854.9/3983.0, min/max reward 16.2/4343.6\n",
      "Saved best model with min rewards 3407.41\n",
      "Num timesteps 640000/1000000.0 Mean Length 851.9\n",
      "Loss Actor -162.4684 Q1/Q2/Critic 25.3443/21.2485/46.59 \n",
      "Last 20 training episodes: mean/median reward 3402.6/3995.8, min/max reward 151.9/4346.9\n",
      "Saved best model with min rewards 3409.26\n",
      "Saved best model with min rewards 3581.03\n",
      "Num timesteps 650000/1000000.0 Mean Length 894.6\n",
      "Loss Actor -180.9410 Q1/Q2/Critic 23.7613/21.6095/45.37 \n",
      "Last 20 training episodes: mean/median reward 3396.6/3954.4, min/max reward 373.3/4346.9\n",
      "Num timesteps 660000/1000000.0 Mean Length 897.0\n",
      "Loss Actor -165.9174 Q1/Q2/Critic 32.4925/30.9595/63.45 \n",
      "Last 20 training episodes: mean/median reward 3415.6/4027.8, min/max reward 373.3/4501.8\n",
      "Saved best model with min rewards 3594.68\n",
      "Saved best model with min rewards 3594.72\n",
      "Saved best model with min rewards 3676.36\n",
      "Saved best model with min rewards 3686.45\n",
      "Saved best model with min rewards 3695.16\n",
      "Saved best model with min rewards 3706.45\n",
      "Saved best model with min rewards 3719.48\n",
      "Num timesteps 670000/1000000.0 Mean Length 935.1\n",
      "Loss Actor -175.5187 Q1/Q2/Critic 45.9338/41.4983/87.43 \n",
      "Last 20 training episodes: mean/median reward 3648.8/4189.3, min/max reward 1612.5/4501.8\n",
      "Saved best model with min rewards 3741.22\n",
      "Saved best model with min rewards 3753.75\n",
      "Saved best model with min rewards 3760.79\n",
      "Saved best model with min rewards 3888.86\n",
      "Saved best model with min rewards 4027.92\n",
      "Saved best model with min rewards 4044.05\n",
      "Saved best model with min rewards 4054.32\n",
      "Saved best model with min rewards 4062.94\n",
      "Saved best model with min rewards 4074.77\n",
      "Num timesteps 680000/1000000.0 Mean Length 980.8\n",
      "Loss Actor -178.8828 Q1/Q2/Critic 15.8306/16.3730/32.2 \n",
      "Last 20 training episodes: mean/median reward 4074.8/4382.3, min/max reward 1612.5/4629.6\n",
      "Saved best model with min rewards 4205.33\n",
      "Saved best model with min rewards 4217.93\n",
      "Saved best model with min rewards 4221.36\n",
      "Num timesteps 690000/1000000.0 Mean Length 935.4\n",
      "Loss Actor -192.8114 Q1/Q2/Critic 25.1314/24.4142/49.55 \n",
      "Last 20 training episodes: mean/median reward 4064.3/4328.8, min/max reward 380.1/4629.6\n",
      "Num timesteps 700000/1000000.0 Mean Length 771.5\n",
      "Loss Actor -194.9260 Q1/Q2/Critic 26.9797/21.1115/48.09 \n",
      "Last 20 training episodes: mean/median reward 3145.2/4178.2, min/max reward 380.1/4648.4\n",
      "Num timesteps 710000/1000000.0 Mean Length 814.0\n",
      "Loss Actor -186.5307 Q1/Q2/Critic 20.4379/12.0809/32.52 \n",
      "Last 20 training episodes: mean/median reward 3245.8/4332.5, min/max reward 251.5/4662.3\n",
      "Num timesteps 720000/1000000.0 Mean Length 789.9\n",
      "Loss Actor -201.1840 Q1/Q2/Critic 24.6762/25.1794/49.86 \n",
      "Last 20 training episodes: mean/median reward 3260.7/4368.5, min/max reward 161.3/4662.3\n",
      "Num timesteps 730000/1000000.0 Mean Length 851.0\n",
      "Loss Actor -198.4001 Q1/Q2/Critic 19.2099/20.7595/39.97 \n",
      "Last 20 training episodes: mean/median reward 3580.6/4455.6, min/max reward 161.3/4737.9\n",
      "Num timesteps 740000/1000000.0 Mean Length 927.4\n",
      "Loss Actor -201.8003 Q1/Q2/Critic 21.0210/17.2321/38.25 \n",
      "Last 20 training episodes: mean/median reward 4144.3/4533.9, min/max reward 478.8/4834.9\n",
      "Saved best model with min rewards 4280.27\n",
      "Num timesteps 750000/1000000.0 Mean Length 805.8\n",
      "Loss Actor -207.1176 Q1/Q2/Critic 21.8453/22.7237/44.57 \n",
      "Last 20 training episodes: mean/median reward 3726.0/4576.4, min/max reward 312.3/4938.2\n",
      "Num timesteps 760000/1000000.0 Mean Length 806.4\n",
      "Loss Actor -203.1396 Q1/Q2/Critic 16.9221/17.9421/34.86 \n",
      "Last 20 training episodes: mean/median reward 3721.3/4542.3, min/max reward 312.3/4999.2\n",
      "Saved best model with min rewards 4371.98\n",
      "Saved best model with min rewards 4380.14\n",
      "Num timesteps 770000/1000000.0 Mean Length 935.4\n",
      "Loss Actor -221.8571 Q1/Q2/Critic 85.1963/101.4757/186.7 \n",
      "Last 20 training episodes: mean/median reward 4380.1/4602.7, min/max reward 1198.1/5079.1\n",
      "Saved best model with min rewards 4395.24\n",
      "Saved best model with min rewards 4402.65\n",
      "Saved best model with min rewards 4426.14\n",
      "Saved best model with min rewards 4595.45\n",
      "Num timesteps 780000/1000000.0 Mean Length 970.5\n",
      "Loss Actor -208.3720 Q1/Q2/Critic 49.9067/53.7478/103.7 \n",
      "Last 20 training episodes: mean/median reward 4594.8/4729.5, min/max reward 2898.9/5079.1\n",
      "Num timesteps 790000/1000000.0 Mean Length 833.6\n",
      "Loss Actor -220.0644 Q1/Q2/Critic 50.4442/47.8703/98.31 \n",
      "Last 20 training episodes: mean/median reward 3928.4/4669.6, min/max reward 63.6/5011.6\n",
      "Num timesteps 800000/1000000.0 Mean Length 833.2\n",
      "Loss Actor -215.8554 Q1/Q2/Critic 24.2727/17.9128/42.19 \n",
      "Last 20 training episodes: mean/median reward 3686.5/4681.3, min/max reward 63.6/5064.3\n",
      "Num timesteps 810000/1000000.0 Mean Length 908.7\n",
      "Loss Actor -220.4314 Q1/Q2/Critic 33.2877/29.6939/62.98 \n",
      "Last 20 training episodes: mean/median reward 4280.5/4801.2, min/max reward 234.8/5109.0\n",
      "Num timesteps 820000/1000000.0 Mean Length 923.1\n",
      "Loss Actor -224.9609 Q1/Q2/Critic 15.4857/18.1785/33.66 \n",
      "Last 20 training episodes: mean/median reward 4466.2/4875.9, min/max reward 234.8/5109.0\n",
      "Num timesteps 830000/1000000.0 Mean Length 873.5\n",
      "Loss Actor -219.2030 Q1/Q2/Critic 19.0280/18.8300/37.86 \n",
      "Last 20 training episodes: mean/median reward 3888.1/4673.6, min/max reward 10.2/5031.2\n",
      "Num timesteps 840000/1000000.0 Mean Length 837.4\n",
      "Loss Actor -234.1007 Q1/Q2/Critic 16.1141/20.2491/36.36 \n",
      "Last 20 training episodes: mean/median reward 3661.6/4630.3, min/max reward 10.2/5024.5\n",
      "Num timesteps 850000/1000000.0 Mean Length 786.9\n",
      "Loss Actor -229.1447 Q1/Q2/Critic 21.5645/18.6805/40.24 \n",
      "Last 20 training episodes: mean/median reward 3683.7/4717.8, min/max reward 12.3/5210.9\n",
      "Num timesteps 860000/1000000.0 Mean Length 810.3\n",
      "Loss Actor -238.8936 Q1/Q2/Critic 27.3139/27.8836/55.2 \n",
      "Last 20 training episodes: mean/median reward 3692.5/4776.0, min/max reward 30.8/5190.1\n",
      "Num timesteps 870000/1000000.0 Mean Length 895.2\n",
      "Loss Actor -228.3577 Q1/Q2/Critic 20.2309/18.7364/38.97 \n",
      "Last 20 training episodes: mean/median reward 4067.4/4886.8, min/max reward 1902.0/5231.5\n",
      "Num timesteps 880000/1000000.0 Mean Length 921.2\n",
      "Loss Actor -251.6069 Q1/Q2/Critic 246.3045/241.4571/487.8 \n",
      "Last 20 training episodes: mean/median reward 4576.7/4994.5, min/max reward 2239.5/5360.2\n",
      "Saved best model with min rewards 4659.61\n",
      "Saved best model with min rewards 4680.59\n",
      "Saved best model with min rewards 4797.58\n",
      "Num timesteps 890000/1000000.0 Mean Length 961.4\n",
      "Loss Actor -229.9324 Q1/Q2/Critic 42.6252/42.9259/85.55 \n",
      "Last 20 training episodes: mean/median reward 4778.0/5043.0, min/max reward 2041.2/5360.2\n",
      "Num timesteps 900000/1000000.0 Mean Length 883.4\n",
      "Loss Actor -239.8723 Q1/Q2/Critic 45.0032/46.4622/91.47 \n",
      "Last 20 training episodes: mean/median reward 4478.8/5029.4, min/max reward 41.1/5433.1\n",
      "Num timesteps 910000/1000000.0 Mean Length 802.8\n",
      "Loss Actor -253.7414 Q1/Q2/Critic 47.5075/51.7201/99.23 \n",
      "Last 20 training episodes: mean/median reward 4061.4/5029.5, min/max reward 226.8/5433.1\n",
      "Num timesteps 920000/1000000.0 Mean Length 818.8\n",
      "Loss Actor -255.8882 Q1/Q2/Critic 22.2596/29.1150/51.37 \n",
      "Last 20 training episodes: mean/median reward 4206.2/5095.4, min/max reward 483.3/5438.7\n",
      "Num timesteps 930000/1000000.0 Mean Length 886.3\n",
      "Loss Actor -256.1880 Q1/Q2/Critic 22.2690/29.9989/52.27 \n",
      "Last 20 training episodes: mean/median reward 4635.0/5190.6, min/max reward 705.0/5464.8\n",
      "Saved best model with min rewards 4995.82\n",
      "Saved best model with min rewards 5004.06\n",
      "Saved best model with min rewards 5094.26\n",
      "Num timesteps 940000/1000000.0 Mean Length 971.2\n",
      "Loss Actor -254.4424 Q1/Q2/Critic 58.2099/59.8151/118.0 \n",
      "Last 20 training episodes: mean/median reward 5094.3/5225.9, min/max reward 3330.5/5511.0\n",
      "Num timesteps 950000/1000000.0 Mean Length 941.9\n",
      "Loss Actor -259.4606 Q1/Q2/Critic 24.7002/23.1209/47.82 \n",
      "Last 20 training episodes: mean/median reward 4770.0/5283.3, min/max reward 1057.3/5511.0\n",
      "Num timesteps 960000/1000000.0 Mean Length 888.1\n",
      "Loss Actor -259.3995 Q1/Q2/Critic 28.9364/28.6209/57.56 \n",
      "Last 20 training episodes: mean/median reward 4608.5/5246.3, min/max reward 884.0/5506.6\n",
      "Num timesteps 970000/1000000.0 Mean Length 940.4\n",
      "Loss Actor -255.6281 Q1/Q2/Critic 32.5816/32.3207/64.9 \n",
      "Last 20 training episodes: mean/median reward 4594.8/5279.0, min/max reward 607.7/5538.4\n",
      "Num timesteps 980000/1000000.0 Mean Length 956.0\n",
      "Loss Actor -277.4514 Q1/Q2/Critic 28.8695/36.6875/65.56 \n",
      "Last 20 training episodes: mean/median reward 4760.2/5334.4, min/max reward 466.2/5548.4\n",
      "Saved best model with min rewards 5126.89\n",
      "Num timesteps 990000/1000000.0 Mean Length 915.0\n",
      "Loss Actor -267.9971 Q1/Q2/Critic 24.8284/23.3167/48.15 \n",
      "Last 20 training episodes: mean/median reward 4727.1/5288.8, min/max reward 466.2/5705.5\n",
      "Num timesteps 1000000/1000000.0 Mean Length 907.1\n",
      "Loss Actor -264.0159 Q1/Q2/Critic 22.0418/25.0699/47.11 \n",
      "Last 20 training episodes: mean/median reward 4679.8/5288.8, min/max reward 1439.7/5705.5\n",
      "Saving last...\n"
     ]
    }
   ],
   "source": [
    "from helpers.envs import make_sync_vec, AutoresetMode\n",
    "\n",
    "num_envs = 1\n",
    "env_id = 'Ant-v5'\n",
    "\n",
    "envs = make_sync_vec(env_id, \n",
    "                    num_envs=num_envs, \n",
    "                    wrappers=(gym.wrappers.RecordEpisodeStatistics,),\n",
    "                    autoreset_mode=AutoresetMode.SAME_STEP)\n",
    "\n",
    "action_size = envs.single_action_space.shape[0]\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "# param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.05, desired_action_stddev=0.2)\n",
    "normal_noise = NormalActionNoise(action_size, 0.1)\n",
    "\n",
    "\n",
    "agent = TD3Agent(envs,  \n",
    "            learning_starts=25000,\n",
    "            mini_batch_size=256,\n",
    "            gamma=0.99,  \n",
    "            tau=0.005,\n",
    "            actor_lr=3e-4,\n",
    "            critic_lr=3e-4,\n",
    "            action_noise=normal_noise,\n",
    "            target_policy_noise=0.2,\n",
    "            target_noise_clip=0.5,\n",
    "            policy_delay=2,\n",
    "            layer_norm=False,\n",
    "            device=DEVICE,\n",
    "            reward_to_achieve=2500)\n",
    "\n",
    "agent.train(total_timesteps=1e6, eval_frequency=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Example - Humanoid-v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000000059604645 0.0800000011920929 0.20000000298023224\n",
      "0.0800000011920929\n",
      "----------------------------------------------------------------------------\n",
      "| Hyperparams                    | Values                                  |\n",
      "----------------------------------------------------------------------------\n",
      "| actor_lr                       | 0.0001                                  |\n",
      "| critic_lr                      | 0.0001                                  |\n",
      "| gamma                          | 0.99                                    |\n",
      "| tau                            | 0.005                                   |\n",
      "| buffer_size                    | 1000000.0                               |\n",
      "| mini_batch_size                | 256                                     |\n",
      "| policy_delay                   | 2                                       |\n",
      "| target_policy_noise            | 0.2                                     |\n",
      "| target_noise_clip              | 0.5                                     |\n",
      "| action_noise                   | 0.0800000011920929                      |\n",
      "----------------------------------------------------------------------------\n",
      "Num timesteps 10000/1000000.0 Mean Length 26.9\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 20 training episodes: mean/median reward 126.0/124.3, min/max reward 83.7/198.7\n",
      "Num timesteps 20000/1000000.0 Mean Length 21.9\n",
      "Loss Actor 0.0000 Q1/Q2/Critic 0.0000/0.0000/0.0 \n",
      "Last 20 training episodes: mean/median reward 101.6/97.2, min/max reward 77.9/153.0\n",
      "Num timesteps 30000/1000000.0 Mean Length 29.6\n",
      "Loss Actor -42.7588 Q1/Q2/Critic 5.1695/7.1479/12.32 \n",
      "Last 20 training episodes: mean/median reward 120.5/118.8, min/max reward 86.5/163.9\n",
      "Num timesteps 40000/1000000.0 Mean Length 32.4\n",
      "Loss Actor -69.7149 Q1/Q2/Critic 10.5399/10.8863/21.43 \n",
      "Last 20 training episodes: mean/median reward 143.9/143.3, min/max reward 132.2/169.0\n",
      "Num timesteps 50000/1000000.0 Mean Length 68.3\n",
      "Loss Actor -149.3720 Q1/Q2/Critic 69.3920/60.4864/129.9 \n",
      "Last 20 training episodes: mean/median reward 350.6/329.3, min/max reward 254.5/649.3\n",
      "Num timesteps 60000/1000000.0 Mean Length 82.8\n",
      "Loss Actor -145.4772 Q1/Q2/Critic 30.8011/32.5236/63.32 \n",
      "Last 20 training episodes: mean/median reward 423.4/420.7, min/max reward 393.3/474.7\n",
      "Num timesteps 70000/1000000.0 Mean Length 85.8\n",
      "Loss Actor -146.2975 Q1/Q2/Critic 27.2871/25.7219/53.01 \n",
      "Last 20 training episodes: mean/median reward 414.8/422.8, min/max reward 352.8/448.1\n",
      "Num timesteps 80000/1000000.0 Mean Length 16.6\n",
      "Loss Actor -113.2891 Q1/Q2/Critic 68.4942/59.8830/128.4 \n",
      "Last 20 training episodes: mean/median reward 74.1/75.7, min/max reward 70.9/76.1\n",
      "Num timesteps 90000/1000000.0 Mean Length 38.6\n",
      "Loss Actor -73.3674 Q1/Q2/Critic 19.8922/17.0386/36.93 \n",
      "Last 20 training episodes: mean/median reward 186.3/184.5, min/max reward 156.5/222.6\n",
      "Num timesteps 100000/1000000.0 Mean Length 51.8\n",
      "Loss Actor -87.2243 Q1/Q2/Critic 10.2134/9.1172/19.33 \n",
      "Last 20 training episodes: mean/median reward 252.0/245.3, min/max reward 217.9/311.3\n",
      "Num timesteps 110000/1000000.0 Mean Length 69.6\n",
      "Loss Actor -101.9765 Q1/Q2/Critic 11.2147/11.4585/22.67 \n",
      "Last 20 training episodes: mean/median reward 316.9/314.6, min/max reward 229.9/469.9\n",
      "Num timesteps 120000/1000000.0 Mean Length 65.1\n",
      "Loss Actor -104.8531 Q1/Q2/Critic 14.6920/13.8758/28.57 \n",
      "Last 20 training episodes: mean/median reward 332.3/326.0, min/max reward 265.9/510.5\n",
      "Num timesteps 130000/1000000.0 Mean Length 68.2\n",
      "Loss Actor -114.4406 Q1/Q2/Critic 16.1378/13.8083/29.95 \n",
      "Last 20 training episodes: mean/median reward 350.6/329.8, min/max reward 270.7/488.2\n",
      "Num timesteps 140000/1000000.0 Mean Length 91.8\n",
      "Loss Actor -132.7507 Q1/Q2/Critic 30.2955/30.4068/60.7 \n",
      "Last 20 training episodes: mean/median reward 435.7/393.1, min/max reward 301.0/885.0\n",
      "Num timesteps 150000/1000000.0 Mean Length 89.2\n",
      "Loss Actor -147.8744 Q1/Q2/Critic 35.8529/34.2642/70.12 \n",
      "Last 20 training episodes: mean/median reward 422.7/367.7, min/max reward 279.4/740.5\n",
      "Num timesteps 160000/1000000.0 Mean Length 71.3\n",
      "Loss Actor -128.8927 Q1/Q2/Critic 35.1381/34.6648/69.8 \n",
      "Last 20 training episodes: mean/median reward 336.9/362.2, min/max reward 88.3/693.6\n",
      "Num timesteps 170000/1000000.0 Mean Length 82.5\n",
      "Loss Actor -129.7034 Q1/Q2/Critic 31.2755/38.8220/70.1 \n",
      "Last 20 training episodes: mean/median reward 390.0/390.9, min/max reward 247.1/520.8\n",
      "Num timesteps 180000/1000000.0 Mean Length 76.2\n",
      "Loss Actor -149.2826 Q1/Q2/Critic 30.7247/39.8814/70.61 \n",
      "Last 20 training episodes: mean/median reward 363.1/360.9, min/max reward 260.4/628.4\n",
      "Num timesteps 190000/1000000.0 Mean Length 79.2\n",
      "Loss Actor -158.6011 Q1/Q2/Critic 47.8237/45.7212/93.54 \n",
      "Last 20 training episodes: mean/median reward 364.0/330.6, min/max reward 232.0/592.7\n",
      "Num timesteps 200000/1000000.0 Mean Length 105.0\n",
      "Loss Actor -157.7117 Q1/Q2/Critic 42.8005/43.8522/86.65 \n",
      "Last 20 training episodes: mean/median reward 500.6/468.8, min/max reward 292.1/940.1\n",
      "Num timesteps 210000/1000000.0 Mean Length 115.0\n",
      "Loss Actor -140.0072 Q1/Q2/Critic 41.0198/51.4268/92.45 \n",
      "Last 20 training episodes: mean/median reward 557.5/498.9, min/max reward 343.2/977.9\n",
      "Num timesteps 220000/1000000.0 Mean Length 68.7\n",
      "Loss Actor -149.6634 Q1/Q2/Critic 38.9949/39.1878/78.18 \n",
      "Last 20 training episodes: mean/median reward 319.9/317.1, min/max reward 268.0/371.2\n",
      "Num timesteps 230000/1000000.0 Mean Length 93.5\n",
      "Loss Actor -151.5659 Q1/Q2/Critic 34.3431/36.7665/71.11 \n",
      "Last 20 training episodes: mean/median reward 447.5/437.5, min/max reward 252.5/669.0\n",
      "Num timesteps 240000/1000000.0 Mean Length 94.8\n",
      "Loss Actor -148.6024 Q1/Q2/Critic 25.7265/24.8281/50.55 \n",
      "Last 20 training episodes: mean/median reward 457.8/463.3, min/max reward 302.4/725.8\n",
      "Num timesteps 250000/1000000.0 Mean Length 110.7\n",
      "Loss Actor -150.7388 Q1/Q2/Critic 34.0636/39.8626/73.93 \n",
      "Last 20 training episodes: mean/median reward 524.4/526.3, min/max reward 289.6/1051.5\n",
      "Num timesteps 260000/1000000.0 Mean Length 113.0\n",
      "Loss Actor -137.1133 Q1/Q2/Critic 37.4817/28.6166/66.1 \n",
      "Last 20 training episodes: mean/median reward 537.3/545.8, min/max reward 271.3/1095.3\n",
      "Num timesteps 270000/1000000.0 Mean Length 90.8\n",
      "Loss Actor -148.3326 Q1/Q2/Critic 30.6511/23.9075/54.56 \n",
      "Last 20 training episodes: mean/median reward 441.2/425.6, min/max reward 312.3/635.7\n",
      "Num timesteps 280000/1000000.0 Mean Length 136.5\n",
      "Loss Actor -161.3261 Q1/Q2/Critic 31.8011/32.9616/64.76 \n",
      "Last 20 training episodes: mean/median reward 676.8/631.2, min/max reward 413.6/1397.2\n",
      "Num timesteps 290000/1000000.0 Mean Length 111.7\n",
      "Loss Actor -160.9635 Q1/Q2/Critic 30.6915/31.6191/62.31 \n",
      "Last 20 training episodes: mean/median reward 557.7/546.9, min/max reward 459.6/687.9\n",
      "Num timesteps 300000/1000000.0 Mean Length 125.0\n",
      "Loss Actor -153.0087 Q1/Q2/Critic 28.4861/29.0394/57.53 \n",
      "Last 20 training episodes: mean/median reward 627.9/561.7, min/max reward 357.1/1027.4\n",
      "Num timesteps 310000/1000000.0 Mean Length 130.4\n",
      "Loss Actor -154.6176 Q1/Q2/Critic 34.4501/32.4823/66.93 \n",
      "Last 20 training episodes: mean/median reward 625.0/515.1, min/max reward 420.1/1806.1\n",
      "Num timesteps 320000/1000000.0 Mean Length 156.3\n",
      "Loss Actor -166.6054 Q1/Q2/Critic 39.6503/50.3093/89.96 \n",
      "Last 20 training episodes: mean/median reward 778.3/736.4, min/max reward 398.8/1286.5\n",
      "Num timesteps 330000/1000000.0 Mean Length 152.7\n",
      "Loss Actor -158.5670 Q1/Q2/Critic 29.1399/25.7530/54.89 \n",
      "Last 20 training episodes: mean/median reward 754.2/704.1, min/max reward 458.3/1318.7\n",
      "Num timesteps 340000/1000000.0 Mean Length 184.6\n",
      "Loss Actor -166.3589 Q1/Q2/Critic 34.9226/30.9742/65.9 \n",
      "Last 20 training episodes: mean/median reward 915.9/814.0, min/max reward 560.9/1410.0\n",
      "Num timesteps 350000/1000000.0 Mean Length 196.0\n",
      "Loss Actor -161.0022 Q1/Q2/Critic 35.0965/41.5630/76.66 \n",
      "Last 20 training episodes: mean/median reward 959.7/849.6, min/max reward 482.9/1985.1\n",
      "Num timesteps 360000/1000000.0 Mean Length 184.9\n",
      "Loss Actor -173.6945 Q1/Q2/Critic 41.2895/38.2679/79.56 \n",
      "Last 20 training episodes: mean/median reward 910.8/772.8, min/max reward 487.4/2500.5\n",
      "Num timesteps 370000/1000000.0 Mean Length 205.5\n",
      "Loss Actor -178.5724 Q1/Q2/Critic 29.7861/39.2812/69.07 \n",
      "Last 20 training episodes: mean/median reward 1014.9/843.6, min/max reward 347.5/2008.9\n",
      "Num timesteps 380000/1000000.0 Mean Length 186.8\n",
      "Loss Actor -187.4385 Q1/Q2/Critic 33.6143/38.8504/72.46 \n",
      "Last 20 training episodes: mean/median reward 927.4/790.6, min/max reward 524.5/1965.9\n",
      "Num timesteps 390000/1000000.0 Mean Length 202.2\n",
      "Loss Actor -187.0987 Q1/Q2/Critic 30.5842/33.5741/64.16 \n",
      "Last 20 training episodes: mean/median reward 1010.3/866.7, min/max reward 461.0/2460.9\n",
      "Num timesteps 400000/1000000.0 Mean Length 313.8\n",
      "Loss Actor -182.3034 Q1/Q2/Critic 37.0167/35.2153/72.23 \n",
      "Last 20 training episodes: mean/median reward 1555.9/1419.7, min/max reward 436.3/4250.5\n",
      "Num timesteps 410000/1000000.0 Mean Length 364.4\n",
      "Loss Actor -187.7467 Q1/Q2/Critic 48.1962/47.5347/95.73 \n",
      "Last 20 training episodes: mean/median reward 1797.4/1499.8, min/max reward 549.6/4963.7\n",
      "Num timesteps 420000/1000000.0 Mean Length 467.6\n",
      "Loss Actor -203.7601 Q1/Q2/Critic 35.9073/33.1407/69.05 \n",
      "Last 20 training episodes: mean/median reward 2304.1/1793.6, min/max reward 877.2/4987.8\n",
      "Num timesteps 430000/1000000.0 Mean Length 382.9\n",
      "Loss Actor -205.7877 Q1/Q2/Critic 39.6617/40.0559/79.72 \n",
      "Last 20 training episodes: mean/median reward 1855.2/1614.1, min/max reward 737.0/3604.1\n",
      "Saved best model with min rewards 2552.95\n",
      "Num timesteps 440000/1000000.0 Mean Length 455.9\n",
      "Loss Actor -208.4629 Q1/Q2/Critic 45.4254/50.1098/95.54 \n",
      "Last 20 training episodes: mean/median reward 2216.3/2124.7, min/max reward 1046.1/4960.1\n",
      "Num timesteps 450000/1000000.0 Mean Length 508.1\n",
      "Loss Actor -201.7966 Q1/Q2/Critic 58.2262/63.1510/121.4 \n",
      "Last 20 training episodes: mean/median reward 2477.2/1976.1, min/max reward 820.5/4991.9\n",
      "Saved best model with min rewards 2619.95\n",
      "Saved best model with min rewards 2720.31\n",
      "Saved best model with min rewards 2791.49\n",
      "Saved best model with min rewards 2959.14\n",
      "Saved best model with min rewards 2981.43\n",
      "Saved best model with min rewards 3050.45\n",
      "Saved best model with min rewards 3251.26\n",
      "Saved best model with min rewards 3278.37\n",
      "Num timesteps 460000/1000000.0 Mean Length 590.6\n",
      "Loss Actor -215.1222 Q1/Q2/Critic 56.8315/54.6845/111.5 \n",
      "Last 20 training episodes: mean/median reward 2904.1/2080.0, min/max reward 1039.9/5004.3\n",
      "Num timesteps 470000/1000000.0 Mean Length 449.7\n",
      "Loss Actor -213.6755 Q1/Q2/Critic 46.8022/41.6162/88.42 \n",
      "Last 20 training episodes: mean/median reward 2195.2/1625.3, min/max reward 462.1/5032.1\n",
      "Num timesteps 480000/1000000.0 Mean Length 637.3\n",
      "Loss Actor -229.1448 Q1/Q2/Critic 47.9153/54.9236/102.8 \n",
      "Last 20 training episodes: mean/median reward 3151.5/3361.3, min/max reward 463.6/5052.8\n",
      "Saved best model with min rewards 3315.98\n",
      "Saved best model with min rewards 3477.72\n",
      "Saved best model with min rewards 3623.53\n",
      "Saved best model with min rewards 3628.73\n",
      "Saved best model with min rewards 3634.18\n",
      "Num timesteps 490000/1000000.0 Mean Length 726.5\n",
      "Loss Actor -229.5585 Q1/Q2/Critic 48.6850/52.3851/101.1 \n",
      "Last 20 training episodes: mean/median reward 3634.2/4992.9, min/max reward 542.9/5056.5\n",
      "Saved best model with min rewards 3639.66\n",
      "Saved best model with min rewards 3641.64\n",
      "Saved best model with min rewards 3644.69\n",
      "Saved best model with min rewards 3689.16\n",
      "Saved best model with min rewards 3864.50\n",
      "Saved best model with min rewards 4069.21\n",
      "Saved best model with min rewards 4069.25\n",
      "Saved best model with min rewards 4239.89\n",
      "Num timesteps 500000/1000000.0 Mean Length 844.9\n",
      "Loss Actor -253.5259 Q1/Q2/Critic 74.6773/62.4413/137.1 \n",
      "Last 20 training episodes: mean/median reward 4239.9/5018.2, min/max reward 542.9/5068.7\n",
      "Saved best model with min rewards 4240.52\n",
      "Saved best model with min rewards 4338.09\n",
      "Saved best model with min rewards 4383.38\n",
      "Saved best model with min rewards 4385.70\n",
      "Saved best model with min rewards 4590.30\n",
      "Saved best model with min rewards 4684.63\n",
      "Num timesteps 510000/1000000.0 Mean Length 931.5\n",
      "Loss Actor -253.0142 Q1/Q2/Critic 65.6648/57.4524/123.1 \n",
      "Last 20 training episodes: mean/median reward 4681.5/5025.8, min/max reward 1471.2/5063.3\n",
      "Saved best model with min rewards 4837.58\n",
      "Saved best model with min rewards 4840.11\n",
      "Num timesteps 520000/1000000.0 Mean Length 880.9\n",
      "Loss Actor -236.5312 Q1/Q2/Critic 54.6172/47.4699/102.1 \n",
      "Last 20 training episodes: mean/median reward 4403.7/4995.0, min/max reward 601.0/5038.1\n",
      "Num timesteps 530000/1000000.0 Mean Length 852.9\n",
      "Loss Actor -273.2256 Q1/Q2/Critic 64.3410/73.3369/137.7 \n",
      "Last 20 training episodes: mean/median reward 4248.8/4985.3, min/max reward 601.0/5025.4\n",
      "Num timesteps 540000/1000000.0 Mean Length 915.2\n",
      "Loss Actor -264.1490 Q1/Q2/Critic 59.0423/72.0458/131.1 \n",
      "Last 20 training episodes: mean/median reward 4551.8/4976.8, min/max reward 631.8/5025.4\n",
      "Num timesteps 550000/1000000.0 Mean Length 958.1\n",
      "Loss Actor -268.0725 Q1/Q2/Critic 60.7646/63.9562/124.7 \n",
      "Last 20 training episodes: mean/median reward 4753.3/4964.0, min/max reward 744.9/5005.3\n",
      "Saved best model with min rewards 4955.97\n",
      "Saved best model with min rewards 4956.07\n",
      "Num timesteps 560000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -277.3004 Q1/Q2/Critic 71.4645/73.8498/145.3 \n",
      "Last 20 training episodes: mean/median reward 4954.5/4954.6, min/max reward 4925.0/4994.4\n",
      "Saved best model with min rewards 4956.48\n",
      "Saved best model with min rewards 4956.62\n",
      "Saved best model with min rewards 4958.50\n",
      "Saved best model with min rewards 4958.54\n",
      "Saved best model with min rewards 4959.56\n",
      "Saved best model with min rewards 4961.20\n",
      "Num timesteps 570000/1000000.0 Mean Length 965.0\n",
      "Loss Actor -283.1591 Q1/Q2/Critic 85.0227/84.3411/169.4 \n",
      "Last 20 training episodes: mean/median reward 4795.1/4960.3, min/max reward 1588.0/5014.9\n",
      "Num timesteps 580000/1000000.0 Mean Length 965.0\n",
      "Loss Actor -283.4238 Q1/Q2/Critic 68.3278/56.1601/124.5 \n",
      "Last 20 training episodes: mean/median reward 4799.8/4964.9, min/max reward 1588.0/5014.9\n",
      "Saved best model with min rewards 4969.83\n",
      "Saved best model with min rewards 4970.92\n",
      "Num timesteps 590000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -287.5533 Q1/Q2/Critic 47.3206/53.9540/101.3 \n",
      "Last 20 training episodes: mean/median reward 4970.9/4973.2, min/max reward 4919.7/5002.2\n",
      "Saved best model with min rewards 4971.06\n",
      "Saved best model with min rewards 4971.14\n",
      "Num timesteps 600000/1000000.0 Mean Length 959.0\n",
      "Loss Actor -293.6436 Q1/Q2/Critic 55.4140/56.6330/112.0 \n",
      "Last 20 training episodes: mean/median reward 4765.2/4973.3, min/max reward 823.8/5004.9\n",
      "Num timesteps 610000/1000000.0 Mean Length 959.0\n",
      "Loss Actor -297.0523 Q1/Q2/Critic 59.0586/49.1395/108.2 \n",
      "Last 20 training episodes: mean/median reward 4767.3/4976.4, min/max reward 823.8/4999.8\n",
      "Saved best model with min rewards 4976.91\n",
      "Saved best model with min rewards 4979.47\n",
      "Num timesteps 620000/1000000.0 Mean Length 986.5\n",
      "Loss Actor -315.4480 Q1/Q2/Critic 72.7147/66.3406/139.1 \n",
      "Last 20 training episodes: mean/median reward 4923.1/4992.1, min/max reward 3628.7/5029.1\n",
      "Num timesteps 630000/1000000.0 Mean Length 844.1\n",
      "Loss Actor -321.2906 Q1/Q2/Critic 44.4564/60.6889/105.1 \n",
      "Last 20 training episodes: mean/median reward 4226.3/4999.5, min/max reward 728.8/5070.8\n",
      "Num timesteps 640000/1000000.0 Mean Length 842.0\n",
      "Loss Actor -306.8154 Q1/Q2/Critic 57.3548/84.5414/141.9 \n",
      "Last 20 training episodes: mean/median reward 4220.2/5003.0, min/max reward 553.3/5071.7\n",
      "Num timesteps 650000/1000000.0 Mean Length 956.0\n",
      "Loss Actor -324.0171 Q1/Q2/Critic 54.8343/67.9599/122.8 \n",
      "Last 20 training episodes: mean/median reward 4778.0/5002.4, min/max reward 553.3/5071.7\n",
      "Num timesteps 660000/1000000.0 Mean Length 907.0\n",
      "Loss Actor -325.1438 Q1/Q2/Critic 49.2631/55.9323/105.2 \n",
      "Last 20 training episodes: mean/median reward 4533.1/4986.6, min/max reward 682.3/5056.2\n",
      "Num timesteps 670000/1000000.0 Mean Length 907.0\n",
      "Loss Actor -319.5328 Q1/Q2/Critic 65.8525/56.1367/122.0 \n",
      "Last 20 training episodes: mean/median reward 4545.1/5006.9, min/max reward 682.3/5056.2\n",
      "Saved best model with min rewards 5006.88\n",
      "Num timesteps 680000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -308.7517 Q1/Q2/Critic 53.5747/62.2250/115.8 \n",
      "Last 20 training episodes: mean/median reward 5004.6/5000.1, min/max reward 4965.6/5035.9\n",
      "Num timesteps 690000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -330.8820 Q1/Q2/Critic 53.4943/62.5447/116.0 \n",
      "Last 20 training episodes: mean/median reward 5006.5/5006.6, min/max reward 4965.6/5033.1\n",
      "Saved best model with min rewards 5008.83\n",
      "Saved best model with min rewards 5009.91\n",
      "Saved best model with min rewards 5011.81\n",
      "Saved best model with min rewards 5013.40\n",
      "Num timesteps 700000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -340.7964 Q1/Q2/Critic 55.7551/48.8106/104.6 \n",
      "Last 20 training episodes: mean/median reward 5009.1/5009.8, min/max reward 4957.3/5043.8\n",
      "Num timesteps 710000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -327.5047 Q1/Q2/Critic 59.3385/68.3871/127.7 \n",
      "Last 20 training episodes: mean/median reward 5007.7/5005.4, min/max reward 4957.3/5051.9\n",
      "Num timesteps 720000/1000000.0 Mean Length 995.9\n",
      "Loss Actor -343.9827 Q1/Q2/Critic 62.1405/62.9970/125.1 \n",
      "Last 20 training episodes: mean/median reward 4989.4/5015.0, min/max reward 4443.7/5058.3\n",
      "Num timesteps 730000/1000000.0 Mean Length 995.9\n",
      "Loss Actor -350.4628 Q1/Q2/Critic 66.7428/73.3865/140.1 \n",
      "Last 20 training episodes: mean/median reward 4995.6/5023.8, min/max reward 4443.7/5077.0\n",
      "Saved best model with min rewards 5026.18\n",
      "Num timesteps 740000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -357.9152 Q1/Q2/Critic 74.1619/63.5586/137.7 \n",
      "Last 20 training episodes: mean/median reward 5020.1/5019.9, min/max reward 4984.8/5077.0\n",
      "Num timesteps 750000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -342.4193 Q1/Q2/Critic 56.9253/52.8311/109.8 \n",
      "Last 20 training episodes: mean/median reward 5014.5/5016.3, min/max reward 4957.6/5054.6\n",
      "Num timesteps 760000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -354.8800 Q1/Q2/Critic 60.2298/55.1737/115.4 \n",
      "Last 20 training episodes: mean/median reward 5017.7/5018.2, min/max reward 4957.6/5058.4\n",
      "Saved best model with min rewards 5027.16\n",
      "Saved best model with min rewards 5027.93\n",
      "Num timesteps 770000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -353.8783 Q1/Q2/Critic 74.4727/69.5373/144.0 \n",
      "Last 20 training episodes: mean/median reward 5026.6/5032.5, min/max reward 4960.4/5058.4\n",
      "Saved best model with min rewards 5030.00\n",
      "Num timesteps 780000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -362.2910 Q1/Q2/Critic 40.2259/45.3688/85.59 \n",
      "Last 20 training episodes: mean/median reward 5029.8/5036.6, min/max reward 4960.4/5056.8\n",
      "Saved best model with min rewards 5031.45\n",
      "Saved best model with min rewards 5034.02\n",
      "Saved best model with min rewards 5035.43\n",
      "Saved best model with min rewards 5037.38\n",
      "Saved best model with min rewards 5038.14\n",
      "Saved best model with min rewards 5040.21\n",
      "Num timesteps 790000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -352.8775 Q1/Q2/Critic 43.3135/53.4958/96.81 \n",
      "Last 20 training episodes: mean/median reward 5039.3/5035.4, min/max reward 4986.7/5093.8\n",
      "Saved best model with min rewards 5041.09\n",
      "Saved best model with min rewards 5041.32\n",
      "Saved best model with min rewards 5042.42\n",
      "Num timesteps 800000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -364.3499 Q1/Q2/Critic 48.7533/45.4624/94.22 \n",
      "Last 20 training episodes: mean/median reward 5041.3/5035.6, min/max reward 4993.4/5093.8\n",
      "Num timesteps 810000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -358.9100 Q1/Q2/Critic 54.6383/39.3578/94.0 \n",
      "Last 20 training episodes: mean/median reward 5020.9/5027.9, min/max reward 4935.2/5075.8\n",
      "Num timesteps 820000/1000000.0 Mean Length 917.8\n",
      "Loss Actor -377.6851 Q1/Q2/Critic 44.2486/49.6184/93.87 \n",
      "Last 20 training episodes: mean/median reward 4607.7/5035.8, min/max reward 673.5/5081.4\n",
      "Num timesteps 830000/1000000.0 Mean Length 917.8\n",
      "Loss Actor -360.7707 Q1/Q2/Critic 46.9606/43.7842/90.74 \n",
      "Last 20 training episodes: mean/median reward 4617.2/5039.1, min/max reward 673.5/5081.4\n",
      "Num timesteps 840000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -373.5568 Q1/Q2/Critic 42.5220/51.0544/93.58 \n",
      "Last 20 training episodes: mean/median reward 5038.9/5038.9, min/max reward 5013.7/5061.8\n",
      "Num timesteps 850000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -369.7341 Q1/Q2/Critic 44.8857/44.5353/89.42 \n",
      "Last 20 training episodes: mean/median reward 5038.2/5039.9, min/max reward 4976.6/5078.8\n",
      "Num timesteps 860000/1000000.0 Mean Length 974.3\n",
      "Loss Actor -374.5390 Q1/Q2/Critic 42.4836/41.9343/84.42 \n",
      "Last 20 training episodes: mean/median reward 4882.7/5028.0, min/max reward 2254.2/5069.6\n",
      "Num timesteps 870000/1000000.0 Mean Length 974.3\n",
      "Loss Actor -360.4734 Q1/Q2/Critic 61.3027/62.7949/124.1 \n",
      "Last 20 training episodes: mean/median reward 4885.2/5025.9, min/max reward 2254.2/5069.6\n",
      "Num timesteps 880000/1000000.0 Mean Length 959.6\n",
      "Loss Actor -359.1238 Q1/Q2/Critic 43.5326/33.2530/76.79 \n",
      "Last 20 training episodes: mean/median reward 4827.2/5029.6, min/max reward 985.5/5080.8\n",
      "Num timesteps 890000/1000000.0 Mean Length 959.6\n",
      "Loss Actor -376.0145 Q1/Q2/Critic 51.2506/56.7863/108.0 \n",
      "Last 20 training episodes: mean/median reward 4815.7/5015.4, min/max reward 985.5/5080.8\n",
      "Num timesteps 900000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -373.4252 Q1/Q2/Critic 43.5343/44.3832/87.92 \n",
      "Last 20 training episodes: mean/median reward 5006.5/5015.6, min/max reward 4947.8/5045.2\n",
      "Num timesteps 910000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -376.7318 Q1/Q2/Critic 57.1235/57.1355/114.3 \n",
      "Last 20 training episodes: mean/median reward 5025.9/5033.3, min/max reward 4947.8/5076.0\n",
      "Num timesteps 920000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -376.6540 Q1/Q2/Critic 39.1532/37.9180/77.07 \n",
      "Last 20 training episodes: mean/median reward 5031.6/5024.7, min/max reward 4970.3/5079.2\n",
      "Num timesteps 930000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -367.9462 Q1/Q2/Critic 59.6444/42.6918/102.3 \n",
      "Last 20 training episodes: mean/median reward 5005.4/5012.3, min/max reward 4914.9/5079.2\n",
      "Num timesteps 940000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -378.0661 Q1/Q2/Critic 57.9661/54.3661/112.3 \n",
      "Last 20 training episodes: mean/median reward 4996.7/4990.2, min/max reward 4914.9/5048.1\n",
      "Num timesteps 950000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -390.7626 Q1/Q2/Critic 46.7148/45.9212/92.64 \n",
      "Last 20 training episodes: mean/median reward 4997.4/5010.2, min/max reward 4890.8/5048.1\n",
      "Num timesteps 960000/1000000.0 Mean Length 988.4\n",
      "Loss Actor -388.6176 Q1/Q2/Critic 41.8043/35.3018/77.11 \n",
      "Last 20 training episodes: mean/median reward 4930.4/4990.9, min/max reward 3771.1/5066.5\n",
      "Num timesteps 970000/1000000.0 Mean Length 988.4\n",
      "Loss Actor -383.2394 Q1/Q2/Critic 41.1883/44.1079/85.3 \n",
      "Last 20 training episodes: mean/median reward 4932.4/5000.2, min/max reward 3771.1/5066.5\n",
      "Num timesteps 980000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -392.7504 Q1/Q2/Critic 61.0545/43.5095/104.6 \n",
      "Last 20 training episodes: mean/median reward 4991.5/5000.3, min/max reward 4912.5/5063.3\n",
      "Num timesteps 990000/1000000.0 Mean Length 1000.0\n",
      "Loss Actor -381.1807 Q1/Q2/Critic 44.4756/56.3987/100.9 \n",
      "Last 20 training episodes: mean/median reward 4972.9/4968.2, min/max reward 4872.7/5063.3\n",
      "Num timesteps 1000000/1000000.0 Mean Length 956.9\n",
      "Loss Actor -406.5071 Q1/Q2/Critic 32.1944/42.3599/74.55 \n",
      "Last 20 training episodes: mean/median reward 4725.3/4935.1, min/max reward 617.1/5019.3\n",
      "Saving last...\n"
     ]
    }
   ],
   "source": [
    "from helpers.envs import make_sync_vec, AutoresetMode\n",
    "\n",
    "num_envs = 1\n",
    "env_id = 'Humanoid-v5'\n",
    "\n",
    "envs = make_sync_vec(env_id, \n",
    "                    num_envs=num_envs, \n",
    "                    wrappers=(gym.wrappers.RecordEpisodeStatistics,),\n",
    "                    autoreset_mode=AutoresetMode.SAME_STEP)\n",
    "\n",
    "action_size = envs.single_action_space.shape[0]\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "# param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.05, desired_action_stddev=0.2)\n",
    "normal_noise = NormalActionNoise(action_size, 0.2)\n",
    "\n",
    "\n",
    "agent = TD3Agent(envs,  \n",
    "            learning_starts=25000,\n",
    "            mini_batch_size=256,\n",
    "            gamma=0.99,  \n",
    "            tau=0.005,\n",
    "            actor_lr=1e-4,\n",
    "            critic_lr=1e-4,\n",
    "            action_noise=normal_noise,\n",
    "            target_policy_noise=0.2,\n",
    "            target_noise_clip=0.5,\n",
    "            policy_delay=2,\n",
    "            layer_norm=False,\n",
    "            device=DEVICE,\n",
    "            reward_to_achieve=2500)\n",
    "\n",
    "agent.train(total_timesteps=1e6, eval_frequency=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate, make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required helpers for the evaluation and video making \n",
    "from helpers.utils import create_evaluation_env_model, eval_policy, record_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Result HalfCheetah-v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 7777.884517675515\n",
      "Episode 2: Total Reward = 7693.718275583373\n",
      "Episode 3: Total Reward = 7844.640212285394\n",
      "Episode 4: Total Reward = 7751.838244559738\n",
      "Episode 5: Total Reward = 7758.778457810196\n",
      "Episode 6: Total Reward = 7721.703191717006\n",
      "Episode 7: Total Reward = 7745.193597935449\n",
      "Episode 8: Total Reward = 7815.85434896124\n",
      "Episode 9: Total Reward = 7709.506961054647\n",
      "Episode 10: Total Reward = 7750.98438867409\n",
      "Mean Reward: 7757.010219625665, Standard Deviation: 43.922908196437724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(7757.010219625665), np.float64(43.922908196437724))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "env, eval_model = create_evaluation_env_model('HalfCheetah-v5', \n",
    "                                              Actor, \n",
    "                                              './runs/HalfCheetah-v5/TD3/actor_lr0.0003_critic_lr0.0003_gamma0.99_nenvs1_batch256_tau0.005_noise0.1_1740935195/best-torch.model') \n",
    "\n",
    "eval_policy(env, eval_model, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7517.198396755457\n",
      "7709.069494753616\n",
      "7798.629301945769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./videos/td3_halfcheetah_v5.mp4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_video(env, \n",
    "             eval_model, \n",
    "             './videos', \n",
    "             'td3_halfcheetah_v5.mp4', \n",
    "             fps=60, min_reward=7700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"../assets/videos/td3_halfcheetah_v5.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Result Ant-v5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 5606.63030836143\n",
      "Episode 2: Total Reward = 5753.800629799539\n",
      "Episode 3: Total Reward = 5690.862440667079\n",
      "Episode 4: Total Reward = 5459.731703107025\n",
      "Episode 5: Total Reward = 5676.736574163247\n",
      "Episode 6: Total Reward = 5686.838428952641\n",
      "Episode 7: Total Reward = 5971.419262065502\n",
      "Episode 8: Total Reward = 5570.92557810914\n",
      "Episode 9: Total Reward = 5562.196856153147\n",
      "Episode 10: Total Reward = 5792.614319025099\n",
      "Mean Reward: 5677.1756100403845, Standard Deviation: 135.21293705815793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(5677.1756100403845), np.float64(135.21293705815793))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env, eval_model = create_evaluation_env_model('Ant-v5', \n",
    "                                              Actor, \n",
    "                                              './runs/Ant-v5/TD3/actor_lr0.0003_critic_lr0.0003_gamma0.99_nenvs1_batch256_tau0.005_noise0.1_1740946542/best-torch.model') \n",
    "\n",
    "eval_policy(env, eval_model, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884.046004249101\n",
      "5825.234078469128\n",
      "5665.173589969115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./videos/td3_ant_v5.mp4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_video(env, \n",
    "             eval_model, \n",
    "             './videos', \n",
    "             'td3_ant_v5.mp4', \n",
    "             fps=60, min_reward=5600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"../assets/videos/td3_ant_v5.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Result Humanoid-v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 4980.794256247066\n",
      "Episode 2: Total Reward = 5012.375757204165\n",
      "Episode 3: Total Reward = 5016.422764708546\n",
      "Episode 4: Total Reward = 5012.425087811564\n",
      "Episode 5: Total Reward = 5002.312039432314\n",
      "Episode 6: Total Reward = 5006.725333832156\n",
      "Episode 7: Total Reward = 5012.731316113164\n",
      "Episode 8: Total Reward = 4975.278831429372\n",
      "Episode 9: Total Reward = 5010.127677489445\n",
      "Episode 10: Total Reward = 4986.335624948871\n",
      "Mean Reward: 5001.552868921666, Standard Deviation: 14.265620113502738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(5001.552868921666), np.float64(14.265620113502738))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env, eval_model = create_evaluation_env_model('Humanoid-v5', \n",
    "                                              Actor, \n",
    "                                              './runs/Humanoid-v5/TD3/actor_lr0.0001_critic_lr0.0001_gamma0.99_nenvs1_batch256_tau0.005_noise0.0800000011920929_1741003349/best-torch.model') \n",
    "\n",
    "eval_policy(env, eval_model, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032.998577512915\n",
      "4845.342665272925\n",
      "4996.054708630489\n",
      "5014.963667259162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./videos/td3_humanoid_v5.mp4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_video(env, \n",
    "             eval_model, \n",
    "             './videos', \n",
    "             'td3_humanoid_v5.mp4', \n",
    "             fps=60, min_reward=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"../assets/videos/td3_humanoid_v5.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "## OFFTOPIC\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review some ways to use gymnasium wrappers for out tasks, look how to setup normalized low dimensions and pixel dimension env for ours tasks, to pass to the agent to train on tasks. Thinking if actually in future define some base class with logging functionality  for all the agents I code as well. Hm, could be interesting idea actually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env1 execution: 1.3231 seconds\n",
      "Env2 execution: 0.6927 seconds\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import AddRenderObservation, TransformObservation, FrameStackObservation,\\\n",
    "      NumpyToTorch, RecordEpisodeStatistics, NormalizeObservation\n",
    "from gymnasium import ObservationWrapper\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "\n",
    "ENV_ID = 'HalfCheetah-v5'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def define_simple_env(env_id, device):\n",
    "    env = gym.make(env_id)\n",
    "    # Add record Episode Statistcs\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    # Add conversion of numpy data to torch \n",
    "    env = NumpyToTorch(env, device)\n",
    "    # Add Normalization \n",
    "    env = NormalizeObservation(env)\n",
    "\n",
    "    return env\n",
    "\n",
    "def define_simple_env2(env_id, device):\n",
    "    env = gym.make(env_id)\n",
    "    # Add record Episode Statistcs\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    # Add Normalization \n",
    "    env = NormalizeObservation(env)\n",
    "    # Add conversion of numpy data to torch \n",
    "    env = NumpyToTorch(env, device)\n",
    "\n",
    "    return env\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(torch.empty(size=(action_dim,), dtype=torch.float32).uniform_(-1, 1))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "env = define_simple_env(ENV_ID, device)\n",
    "env2 = define_simple_env2(ENV_ID, device)\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(env), number=1000)\n",
    "time2 = timeit.timeit(lambda: experiment(env2), number=1000)\n",
    "\n",
    "print(f\"Env1 execution: {time1:.4f} seconds\")\n",
    "print(f\"Env2 execution: {time2:.4f} seconds\") # 2x faster, better do normalize before transforming to torch, \n",
    "# too many transforms otherwise, also data of obs gets fucked otherwise returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the data with simple env2, how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NumpyToTorch<NormalizeObservation<RecordEpisodeStatistics<TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv<HalfCheetah-v5>>>>>>>>\n",
      "Box(-1.0, 1.0, (6,), float32)\n",
      "Box(-inf, inf, (17,), float32)\n",
      "tensor([-0.7766, -1.6027, -0.4736,  1.3003,  1.1561, -0.4857,  0.8846, -1.2226,\n",
      "        -0.1367,  2.4390,  0.6243,  0.3367, -0.7424, -0.4265, -1.4405,  0.8717,\n",
      "         0.4698])\n",
      "-0.21953247910958676\n"
     ]
    }
   ],
   "source": [
    "env = define_simple_env2(ENV_ID, device)\n",
    "obs, reward = experiment(env)\n",
    "\n",
    "\n",
    "print(env)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "\n",
    "print(obs)\n",
    "print(reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review how same will work with mps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Env execution: 3.5361 seconds\n",
      "CPU Torch Env execution: 1.8292 seconds\n",
      "No torch env execution: 1.7196 seconds\n"
     ]
    }
   ],
   "source": [
    "class NumpyToTorchMPS(gym.Wrapper):\n",
    "    \"\"\"Converts NumPy-based environment inputs/outputs to PyTorch Tensors, with MPS compatibility.\"\"\"\n",
    "\n",
    "    def __init__(self, env: gym.Env,  device: str | torch.device = \"cpu\"):\n",
    "        super().__init__(env)\n",
    "        self.device = torch.device(device)\n",
    "        self.obs_tensor = torch.zeros(env.observation_space.shape, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def _to_torch(self, value):\n",
    "        if isinstance(value, np.ndarray):\n",
    "            self.obs_tensor.copy_(torch.tensor(value, dtype=torch.float32, device=self.device))\n",
    "            return self.obs_tensor\n",
    "        return value\n",
    "\n",
    "    def _to_numpy(self, value):\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            # Convert back to NumPy only when absolutely necessary\n",
    "            return value.cpu().numpy()\n",
    "        return value\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Resets the environment and returns PyTorch-based observations.\"\"\"\n",
    "        obs, info = self.env.reset(seed=seed, options=self._to_numpy(options) if options else None)\n",
    "        return self._to_torch(obs), info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Takes a step using a PyTorch action and returns PyTorch-based observations.\"\"\"\n",
    "        obs, reward, terminated, truncated, info = self.env.step(self._to_numpy(action))\n",
    "        return (\n",
    "            self._to_torch(obs),\n",
    "            float(reward),\n",
    "            bool(terminated),\n",
    "            bool(truncated),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "def define_simple_env(env_id, device):\n",
    "    env = gym.make(env_id)\n",
    "    # Add record Episode Statistcs\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    # Add Normalization \n",
    "    env = NormalizeObservation(env)\n",
    "    # Add conversion of numpy data to torch \n",
    "    env = NumpyToTorchMPS(env, device)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "def define_simple_env2(env_id, device):\n",
    "    env = gym.make(env_id)\n",
    "    # Add record Episode Statistcs\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    # Add Normalization \n",
    "    env = NormalizeObservation(env)\n",
    "\n",
    "    return env\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(torch.empty(size=(action_dim,), dtype=torch.float32).uniform_(-1, 1))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "def experiment2(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(np.random.uniform(low=-1.0, high=1.0, size=action_dim))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "ENV_ID = 'Humanoid-v5'\n",
    "device = torch.device('mps')\n",
    "\n",
    "env = define_simple_env(ENV_ID, device)\n",
    "env2 = define_simple_env2(ENV_ID, device)\n",
    "env3 = define_simple_env(ENV_ID, torch.device('cpu'))\n",
    "# obs, reward = experiment(env)\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(env), number=1000)\n",
    "time2 = timeit.timeit(lambda: experiment2(env2), number=1000)\n",
    "time3 = timeit.timeit(lambda: experiment(env3), number=1000)\n",
    "\n",
    "\n",
    "print(f\"MPS Env execution: {time1:.4f} seconds\")\n",
    "print(f\"CPU Torch Env execution: {time3:.4f} seconds\")\n",
    "print(f\"No torch env execution: {time2:.4f} seconds\")\n",
    "\n",
    "# print(obs)\n",
    "# print(reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do some tests now with more complex env and see how it works, like with images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Pixels Env execution: 3.7894 seconds\n",
      "CPU Pixels Env execution: 3.5141 seconds\n",
      "No torch pixels env execution: 3.4465 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gymnasium.wrappers import AddRenderObservation, FrameStackObservation,\\\n",
    "      NumpyToTorch, RecordEpisodeStatistics, NormalizeObservation\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"]=\"glfw\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"glfw\"\n",
    "\n",
    "\n",
    "class PreprocessObservation(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1.0, shape=(84, 84), dtype=np.float32)\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        # Convert to grayscale\n",
    "        observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "        # Resize to 84x84\n",
    "        observation = cv2.resize(observation, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        # Normalize to [0, 1]\n",
    "        observation = observation / 255.0\n",
    "        return observation\n",
    "\n",
    "def create_env_preprocess(env_id):\n",
    "    env = gym.make(env_id, render_mode='rgb_array')\n",
    "    # Change env to use render observation\n",
    "    env = AddRenderObservation(env, render_only=True)\n",
    "    # Add our own preprocess observation \n",
    "    env = PreprocessObservation(env)\n",
    "    # print(env.observation_space)\n",
    "    # Stack the last 4 frames\n",
    "    env = FrameStackObservation(env, stack_size=4)\n",
    "    return env\n",
    "\n",
    "ENV_ID = 'HalfCheetah-v5'\n",
    "device1 = torch.device('mps')\n",
    "device2 = torch.device('cpu')\n",
    "\n",
    "env = create_env_preprocess(ENV_ID)\n",
    "# Add conversion of numpy data to torch \n",
    "envmps = NumpyToTorchMPS(env, device1)\n",
    "envcpu = NumpyToTorchMPS(env, device2)\n",
    "\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(envmps), number=100)\n",
    "time2 = timeit.timeit(lambda: experiment(envcpu), number=100)\n",
    "time3 = timeit.timeit(lambda: experiment2(env), number=100)\n",
    "\n",
    "print(f\"MPS Pixels Env execution: {time1:.4f} seconds\")\n",
    "print(f\"CPU Pixels Env execution: {time2:.4f} seconds\")\n",
    "print(f\"No torch pixels env execution: {time3:.4f} seconds\")\n",
    "\n",
    "# experiment(envmps)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with running parallel 4 env and compare data, not complext but simple HalfCheetah "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Pixels Env execution: 15.8182 seconds\n",
      "CPU Pixels Env execution: 14.5051 seconds\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.vector import SyncVectorEnv\n",
    "from gymnasium.wrappers.vector import NumpyToTorch\n",
    "from gymnasium.vector import VectorWrapper, VectorEnv\n",
    "from gymnasium.core import ActType, ObsType\n",
    "from gymnasium.vector.vector_env import ArrayType\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "num_envs = 4\n",
    "env_id = 'HalfCheetah-v5'\n",
    "device1 = torch.device('mps')\n",
    "device2 = torch.device('cpu')\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"]=\"glfw\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"glfw\"\n",
    "\n",
    "class NumpyToTorchMPS(VectorWrapper):\n",
    "    \"\"\"Wraps a numpy-based vector environment so that it can be interacted with through PyTorch Tensors on MPS.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: VectorEnv, device: str | torch.device = \"mps\"):\n",
    "        \"\"\"Wrapper class to change inputs and outputs of the environment to PyTorch tensors for MPS.\n",
    "\n",
    "        Args:\n",
    "            env: The numpy-based vector environment to wrap\n",
    "            device: The device (e.g., \"mps\") the torch Tensors should be moved to\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.device: torch.device = torch.device(device)\n",
    "\n",
    "    def step(\n",
    "        self, actions: ActType\n",
    "    ) -> tuple[ObsType, ArrayType, ArrayType, ArrayType, dict]:\n",
    "        \"\"\"Converts PyTorch-based actions to NumPy and returns PyTorch-based results.\n",
    "\n",
    "        Args:\n",
    "            actions: A PyTorch-based action tensor\n",
    "\n",
    "        Returns:\n",
    "            PyTorch-based Tensor next observation, reward, termination, truncation, and extra info\n",
    "        \"\"\"\n",
    "        # Convert PyTorch tensor actions to NumPy\n",
    "        np_actions = actions.cpu().numpy()\n",
    "        obs, reward, terminated, truncated, info = self.env.step(np_actions)\n",
    "\n",
    "        # Convert results back to PyTorch tensors on MPS\n",
    "        return (\n",
    "            torch.as_tensor(obs, dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(reward, dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(terminated, dtype=torch.bool, device=self.device),\n",
    "            torch.as_tensor(truncated, dtype=torch.bool, device=self.device),\n",
    "            self._to_torch(info),\n",
    "        )\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: int | list[int] | None = None,\n",
    "        options: dict[str, Any] | None = None,\n",
    "    ) -> tuple[ObsType, dict[str, Any]]:\n",
    "        \"\"\"Resets the environment and returns PyTorch-based results.\n",
    "\n",
    "        Args:\n",
    "            seed: The seed for resetting the environment\n",
    "            options: The options for resetting the environment\n",
    "\n",
    "        Returns:\n",
    "            PyTorch-based observations and info\n",
    "        \"\"\"\n",
    "        if options:\n",
    "            options = self._to_numpy(options)\n",
    "\n",
    "        # Reset environment and convert results to PyTorch tensors\n",
    "        obs, info = self.env.reset(seed=seed, options=options)\n",
    "        return self._to_torch(obs), self._to_torch(info)\n",
    "\n",
    "    def _to_torch(self, value):\n",
    "        \"\"\"Helper function to convert NumPy values to PyTorch tensors.\"\"\"\n",
    "        if isinstance(value, np.ndarray):\n",
    "            return torch.tensor(value, dtype=torch.float32, device=self.device)\n",
    "        elif isinstance(value, dict):\n",
    "            return {k: self._to_torch(v) for k, v in value.items()}\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            return type(value)(self._to_torch(v) for v in value)\n",
    "        return value\n",
    "\n",
    "    def _to_numpy(self, value):\n",
    "        \"\"\"Helper function to convert PyTorch tensors back to NumPy.\"\"\"\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            return value.cpu().numpy()\n",
    "        elif isinstance(value, dict):\n",
    "            return {k: self._to_numpy(v) for k, v in value.items()}\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            return type(value)(self._to_numpy(v) for v in value)\n",
    "        return value\n",
    "\n",
    "def create_env_preprocess_func(env_id):\n",
    "        def _init():\n",
    "            env = gym.make(env_id)\n",
    "            # Add record Episode Statistcs\n",
    "            env = RecordEpisodeStatistics(env)\n",
    "            # Add Normalization \n",
    "            env = NormalizeObservation(env)\n",
    "            return env\n",
    "        return _init\n",
    "\n",
    "def create_env_preprocess_func_2(env_id):\n",
    "    def _init():\n",
    "        env = gym.make(env_id, render_mode='rgb_array')\n",
    "        # Change env to use render observation\n",
    "        env = AddRenderObservation(env, render_only=True)\n",
    "        # Add our own preprocess observation \n",
    "        env = PreprocessObservation(env)\n",
    "        # print(env.observation_space)\n",
    "        # Stack the last 4 frames\n",
    "        env = FrameStackObservation(env, stack_size=4)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(torch.empty(size=action_dim, dtype=torch.float32).uniform_(-1, 1))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "envs1 = SyncVectorEnv([create_env_preprocess_func_2(env_id) for _ in range(num_envs)]) \n",
    "envs1 = NumpyToTorchMPS(envs1, device1)\n",
    "envs2 = SyncVectorEnv([create_env_preprocess_func_2(env_id) for _ in range(num_envs)]) \n",
    "envs2 = NumpyToTorchMPS(envs2, device2)\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(envs1), number=100)\n",
    "time2 = timeit.timeit(lambda: experiment(envs2), number=100)\n",
    "\n",
    "print(f\"MPS Pixels Env execution: {time1:.4f} seconds\")\n",
    "print(f\"CPU Pixels Env execution: {time2:.4f} seconds\") # well that's pathetic aaaa\n",
    "# With HalfCheetah 6.6x perfomance gain on CPU on 4 env\n",
    "# With Humanoid 5.95x perfomance gain on CPU\n",
    "# With HalfCheetah 3.45x perfomance gain on CPU on 16 env\n",
    "# With Humanoid 2.51x perfomance gain on CPU on 16 env\n",
    "# With Humanoid 1.82x perfomance gain on CPU on 32 env\n",
    "# With HalfCheetah pixels perfomace MPS 15.81 vs CPU 14.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment similar with the envs for the pixels, but use this time deepmind gym and see if its faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Pixels Env execution: 3.3559 seconds\n",
      "CPU Pixels Env execution: 3.0688 seconds\n",
      "No torch pixels env execution: 2.9904 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import timeit\n",
    "import cv2\n",
    "\n",
    "from helpers import dmc2gym\n",
    "import gymnasium as gym\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import FrameStackObservation\n",
    "\n",
    "class NumpyToTorchMPS(gym.Wrapper):\n",
    "    \"\"\"Converts NumPy-based environment inputs/outputs to PyTorch Tensors, with MPS compatibility.\"\"\"\n",
    "\n",
    "    def __init__(self, env: gym.Env,  device: str | torch.device = \"cpu\"):\n",
    "        super().__init__(env)\n",
    "        self.device = torch.device(device)\n",
    "        self.obs_tensor = torch.zeros(env.observation_space.shape, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def _to_torch(self, value):\n",
    "        if isinstance(value, np.ndarray):\n",
    "            self.obs_tensor.copy_(torch.tensor(value, dtype=torch.float32, device=self.device))\n",
    "            return self.obs_tensor\n",
    "        return value\n",
    "\n",
    "    def _to_numpy(self, value):\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            # Convert back to NumPy only when absolutely necessary\n",
    "            return value.cpu().numpy()\n",
    "        return value\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Resets the environment and returns PyTorch-based observations.\"\"\"\n",
    "        obs, info = self.env.reset(seed=seed, options=self._to_numpy(options) if options else None)\n",
    "        return self._to_torch(obs), info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Takes a step using a PyTorch action and returns PyTorch-based observations.\"\"\"\n",
    "        obs, reward, terminated, truncated, info = self.env.step(self._to_numpy(action))\n",
    "        return (\n",
    "            self._to_torch(obs),\n",
    "            float(reward),\n",
    "            bool(terminated),\n",
    "            bool(truncated),\n",
    "            info,\n",
    "        )\n",
    "\n",
    "class PreprocessObservation(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1.0, shape=(84, 84), dtype=np.float32)\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        # print(observation.shape)\n",
    "        # Convert to grayscale\n",
    "        observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "        # Normalize to [0, 1]\n",
    "        observation = observation / 255.0\n",
    "        return observation\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(torch.empty(size=(action_dim,), dtype=torch.float32).uniform_(-1, 1))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "def experiment2(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(np.random.uniform(low=-1.0, high=1.0, size=action_dim))\n",
    "    \n",
    "    return obs, reward\n",
    "# print(suite.ALL_TASKS)\n",
    "\n",
    "env = dmc2gym.DMCWrapper(domain_name=\"cheetah\", task_name=\"run\", rendering='egl', frame_skip=4, from_pixels=True, height=84, width=84)\n",
    "env = PreprocessObservation(env)\n",
    "env = FrameStackObservation(env, stack_size=4)\n",
    "device1 = torch.device('mps')\n",
    "device2 = torch.device('cpu')\n",
    "\n",
    "# Add conversion of numpy data to torch \n",
    "envmps = NumpyToTorchMPS(env, device1)\n",
    "envcpu = NumpyToTorchMPS(env, device2)\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(envmps), number=100)\n",
    "time2 = timeit.timeit(lambda: experiment(envcpu), number=100)\n",
    "time3 = timeit.timeit(lambda: experiment2(env), number=100)\n",
    "\n",
    "print(f\"MPS Pixels Env execution: {time1:.4f} seconds\")\n",
    "print(f\"CPU Pixels Env execution: {time2:.4f} seconds\")\n",
    "print(f\"No torch pixels env execution: {time3:.4f} seconds\")\n",
    "#MPS Pixels Env execution: 3.7953 seconds  vs 3.20 -> 18% improvement\n",
    "# CPU Pixels Env execution: 3.4143 seconds vs 2.97 -> 15% improvement\n",
    "# No torch pixels env execution: 3.4137 seconds vs 2.96 -> 15% improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape[-1]\n",
    "\n",
    "    for i in range(100):\n",
    "        obs, _, _, _, _ = env.step(np.random.uniform(low=-1.0, high=1.0, size=action_dim))\n",
    "    \n",
    "    return obs\n",
    "\n",
    "obs = experiment(env)\n",
    "\n",
    "plt.figure(figsize=(12, 8)) # 12 inches wide and 6 inch tall\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4, i+1)\n",
    "    plt.imshow(obs[i])\n",
    "    plt.title(f'Gym Wrappers Obs{i}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with Vectorized NumpyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.vector import SyncVectorEnv\n",
    "from gymnasium.wrappers.vector import NumpyToTorch\n",
    "from gymnasium.vector import VectorWrapper, VectorEnv\n",
    "from gymnasium.core import ActType, ObsType\n",
    "from gymnasium.vector.vector_env import ArrayType\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "num_envs = 4\n",
    "env_id = 'HalfCheetah-v5'\n",
    "device1 = torch.device('mps')\n",
    "device2 = torch.device('cpu')\n",
    "\n",
    "class NumpyToTorchMPSVec(VectorWrapper):\n",
    "    \"\"\"Wraps a numpy-based vector environment so that it can be interacted with through PyTorch Tensors on MPS.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: VectorEnv, device: str | torch.device = \"mps\"):\n",
    "        \"\"\"Wrapper class to change inputs and outputs of the environment to PyTorch tensors for MPS.\n",
    "\n",
    "        Args:\n",
    "            env: The numpy-based vector environment to wrap\n",
    "            device: The device (e.g., \"mps\") the torch Tensors should be moved to\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.device: torch.device = torch.device(device)\n",
    "\n",
    "    def step(\n",
    "        self, actions: ActType\n",
    "    ) -> tuple[ObsType, ArrayType, ArrayType, ArrayType, dict]:\n",
    "        \"\"\"Converts PyTorch-based actions to NumPy and returns PyTorch-based results.\n",
    "\n",
    "        Args:\n",
    "            actions: A PyTorch-based action tensor\n",
    "\n",
    "        Returns:\n",
    "            PyTorch-based Tensor next observation, reward, termination, truncation, and extra info\n",
    "        \"\"\"\n",
    "        # Convert PyTorch tensor actions to NumPy\n",
    "        np_actions = actions.cpu().numpy()\n",
    "        obs, reward, terminated, truncated, info = self.env.step(np_actions)\n",
    "\n",
    "        # Convert results back to PyTorch tensors on MPS\n",
    "        return (\n",
    "            torch.as_tensor(obs, dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(reward, dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(terminated, dtype=torch.bool, device=self.device),\n",
    "            torch.as_tensor(truncated, dtype=torch.bool, device=self.device),\n",
    "            self._to_torch(info),\n",
    "        )\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: int | list[int] | None = None,\n",
    "        options: dict[str, Any] | None = None,\n",
    "    ) -> tuple[ObsType, dict[str, Any]]:\n",
    "        \"\"\"Resets the environment and returns PyTorch-based results.\n",
    "\n",
    "        Args:\n",
    "            seed: The seed for resetting the environment\n",
    "            options: The options for resetting the environment\n",
    "\n",
    "        Returns:\n",
    "            PyTorch-based observations and info\n",
    "        \"\"\"\n",
    "        if options:\n",
    "            options = self._to_numpy(options)\n",
    "\n",
    "        # Reset environment and convert results to PyTorch tensors\n",
    "        obs, info = self.env.reset(seed=seed, options=options)\n",
    "        return self._to_torch(obs), self._to_torch(info)\n",
    "\n",
    "    def _to_torch(self, value):\n",
    "        \"\"\"Helper function to convert NumPy values to PyTorch tensors.\"\"\"\n",
    "        if isinstance(value, np.ndarray):\n",
    "            return torch.tensor(value, dtype=torch.float32, device=self.device)\n",
    "        elif isinstance(value, dict):\n",
    "            return {k: self._to_torch(v) for k, v in value.items()}\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            return type(value)(self._to_torch(v) for v in value)\n",
    "        return value\n",
    "\n",
    "    def _to_numpy(self, value):\n",
    "        \"\"\"Helper function to convert PyTorch tensors back to NumPy.\"\"\"\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            return value.cpu().numpy()\n",
    "        elif isinstance(value, dict):\n",
    "            return {k: self._to_numpy(v) for k, v in value.items()}\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            return type(value)(self._to_numpy(v) for v in value)\n",
    "        return value\n",
    "\n",
    "def create_env_preprocess_func(env_id):\n",
    "        def _init():\n",
    "            env = dmc2gym.DMCWrapper(domain_name=\"cheetah\", task_name=\"run\", rendering='egl', frame_skip=4, from_pixels=True, height=84, width=84)\n",
    "            env = PreprocessObservation(env)\n",
    "            env = FrameStackObservation(env, stack_size=4)\n",
    "            return env\n",
    "        return _init\n",
    "\n",
    "def experiment(env):\n",
    "    env.reset()\n",
    "\n",
    "    action_dim = env.action_space.shape\n",
    "\n",
    "    for i in range(10):\n",
    "        obs, reward, _, _, _ = env.step(torch.empty(size=action_dim, dtype=torch.float32).uniform_(-1, 1))\n",
    "    \n",
    "    return obs, reward\n",
    "\n",
    "envs1 = SyncVectorEnv([create_env_preprocess_func(env_id) for _ in range(num_envs)]) \n",
    "envs1 = NumpyToTorchMPSVec(envs1, device1)\n",
    "envs2 = SyncVectorEnv([create_env_preprocess_func(env_id) for _ in range(num_envs)]) \n",
    "envs2 = NumpyToTorchMPSVec(envs2, device2)\n",
    "print(envs1.observation_space, envs1.num_envs)\n",
    "\n",
    "time1 = timeit.timeit(lambda: experiment(envs1), number=100)\n",
    "time2 = timeit.timeit(lambda: experiment(envs2), number=100)\n",
    "\n",
    "print(f\"MPS Pixels Env execution: {time1:.4f} seconds\")\n",
    "print(f\"CPU Pixels Env execution: {time2:.4f} seconds\") # well that's pathetic aaaa\n",
    "### Comparison to similar gymnasium setup\n",
    "#MPS Pixels Env execution: 15.8182 seconds => 14.26 egl(10% faster) | glf -14.7\n",
    "#CPU Pixels Env execution: 14.5051 seconds => 12.92 egl(12$% faster) | glf -12.8\n",
    "# In the end it all looks like similar perfomanace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-Odyssey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
